{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Challenge_ Day2.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python385jvsc74a57bd0c30745a67ab3077685183c6616f760120387d2e186c7e6a99675e86d34cdfa12","display_name":"Python 3.8.5 64-bit ('base': conda)"},"language_info":{"name":"python","version":"3.8.5"}},"cells":[{"cell_type":"markdown","metadata":{"id":"zDwep1K8Erxl"},"source":["**Project:** Data Minining Project for  X company"]},{"cell_type":"markdown","metadata":{"id":"d7-ii3uyI8KY"},"source":["The CRISP-DM Framework\n","\n","\n","The CRISP-DM methodology provides a structured approach to planning a data mining project. It is a robust and well-proven methodology.\n","* Business understanding (BU): Determine Business Objectives, Assess Situation, Determine Data Mining Goals, Produce Project Plan\n","\n","* Data understanding (DU): Collect Initial Data, Describe Data, Explore Data, Verify Data Quality\n","\n","* Data preparation (DP): Select Data, Clean Data, Construct Data, Integrate Data\n","\n","* Modeling (M): Select modeling technique, Generate Test Design, Build Model, Assess Model\n","*  Evaluation (E): Evaluate Results, Review Process, Determine Next Steps\n","*  Deployment (D): Plan Deployment, Plan Monitoring and Maintenance, Produce Final Report, Review Project\n","\n","\n","References:\n","\n","[What is the CRISP-DM methodology?](https://www.sv-europe.com/crisp-dm-methodology/)\n","\n","[Introduction to CRISP DM Framework for Data Science and Machine Learning](https://www.linkedin.com/pulse/chapter-1-introduction-crisp-dm-framework-data-science-anshul-roy/)"]},{"cell_type":"markdown","metadata":{"id":"5lo7Ml7tMQOf"},"source":["**Data Set**\n","### The data is for company X which is trying to control attrition. \n","### There are two sets of data: \"Existing employees\" and \"Employees who have left\". The following attributes are available for every employee.\n","\n","\n","*   Satisfaction Level\n","\n","*   Last evaluation\n","\n","*   Number of projects\n","\n","*   Average monthly hours\n","\n","*   Time spent at the company\n","*   Whether they have had a work accident\n","\n","\n","*  Whether they have had a promotion in the last 5 years\n","\n","\n","*   Departments (column sales)\n","\n","\n","*   Salary\n","\n","\n","*  Whether the employee has left\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"sjSj2A2sSph_"},"source":["**Your Role**\n"," \n","\n","*   As data science team member X company asked you to answer this two questions.\n","*  What type of employees is leaving? \n","\n","*   Determine which employees are prone to leave next.\n","\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"ajdEVA7LiBUp"},"source":["Business Understanding\n","\n","---\n","\n","This step mostly focuses on understanding the Business in all the different aspects. It follows the below different steps.\n","\n","\n","\n","\n","* Identify the goal and frame the business problem.\n","* Prepare Analytical Goal i.e. what type of performance metric and loss function to use\n","* Gather information on resource, constraints, assumptions, risks etc\n","* Gather information on resource, constraints, assumptions, risks etc\n","*   Prepare Work Flow Chart"]},{"cell_type":"markdown","metadata":{"id":"J4MwiCYzj2_u"},"source":["### Write the main objectives of this project in your words?\n","minimum of 100 characters"]},{"cell_type":"code","metadata":{"id":"STyLda45j1Mf"},"source":["main_objectives ='''\n","The main objectives of this project are:\n","  * to keep employees form leaving X company\n","  * to increase employees' continuity in X company\n","  * to identify the factors which affect employee's stay in X company so that decisions could be taken to     control attrition\n","'''"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"CuOlxLxKMOLI"},"source":["assert len(main_objectives) > 100 \n","### BEGIN HIDDEN TESTS\n","assert len(main_objectives) > 80 \n","### END HIDDEN TESTS"],"execution_count":3,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"NyXeNxlCkbaw"},"source":["### Outline the different data analysis steps you will follow to carry out the project"]},{"cell_type":"code","metadata":{"id":"rC-tl8sUksQq"},"source":["dm_outline = '''\n","n order to carry out data analysis for this project, I will follow these steps.\n","  1. Understand the business problem\n","  2. Extract and understand the datasets\n","  3. Handle missing values and outliers\n","  4. Transform the data, if necessary\n","  5. Perform feature engineering tasks\n","  6. Split the data into training, validation and testing sets\n","  7. Build classifier models\n","  8. Measure the models' results and choose the best one\n","  9. Generate recommendation reports\n","'''"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"-K1mWuDoksTk"},"source":["assert len(dm_outline) > 100 \n","### BEGIN HIDDEN TESTS\n","assert len(dm_outline) > 70 \n","### END HIDDEN TESTS"],"execution_count":5,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"pmUDFG1wkzUy"},"source":["### What metrics will you use to measure the performance of your data analysis model? \n","Write the equations of the metrics here"]},{"cell_type":"markdown","metadata":{"id":"KCNulojKk_BP"},"source":["e.g. Precision = $\\frac{TP}{(TP + FP)}$\n","\n"]},{"cell_type":"markdown","metadata":{"id":"vLS2YHoRk_EK"},"source":["Why do you choose these metrics? minimum of 100 characters"]},{"cell_type":"code","metadata":{"id":"LSynT14KlPSJ"},"source":["why_metrics = '''Add your answer text here\n","you can create python string using (') or (\") or 3('), like the text here. The 3(') string can be used \n","to write paragraphs, comments in the beginning of functions, etc.. Your answer to the above question \n","should replace this text.\n","'''"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"yr-Mk0E8lPVJ"},"source":["assert len(why_metrics) > 100 \n","### BEGIN HIDDEN TESTS\n","assert len(why_metrics) > 80 \n","### END HIDDEN TESTS"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"aAo19Ip6lUtm"},"source":["### How would you know if your data analysis work is a success or not?\n","minimum of 100 characters"]},{"cell_type":"code","metadata":{"id":"HESsiXW5llX-"},"source":["how_success = '''\n","I would know that my data analysis work is a success if my audience,X company, accepts the results that arise from it. In other words, it would be a success if my data analysis model could successfully predict atleast the majority(a precentage decided by X company) of the employeees who leave X company.\n","'''"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"FdUoiMIOlmXq"},"source":["assert len(how_success) > 100 \n","### BEGIN HIDDEN TESTS\n","assert len(how_success) > 80 \n","### END HIDDEN TESTS"],"execution_count":7,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DQE6dqo6l1TZ"},"source":["## What kind of challenges do you expect in your analysis?\n","List at least 3 challenges"]},{"cell_type":"code","metadata":{"id":"WrAhBQhQl8Lh"},"source":["challenge_text = '''\n","The main challenges that I expect in my data analysis process are:\n","  1. Small amount of data\n","  2. Missing values that are hard to fill which can reduce my success\n","  3. Undiscovered but relevant features that are hard to engineer\n","  4. Model overfitting\n","'''"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"EedHa-Pll8X7"},"source":["assert len(challenge_text) > 100 \n","### BEGIN HIDDEN TESTS\n","assert len(how_success) > 80 \n","### END HIDDEN TESTS"],"execution_count":9,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ZcJ8M6uWDeSE"},"source":["<h2>Using the processed twitter data from yesterday's challenge</h2>.\n","\n","\n","- Form a new data frame (named `cleanTweet`), containing columns $\\textbf{clean-text}$ and $\\textbf{polarity}$.\n","\n","- Write a function `text_category` that takes a value `p` and returns, depending on the value of p, a string `'positive'`, `'negative'` or `'neutral'`.\n","\n","- Apply this function (`text_category`) on the $\\textbf{polarity}$ column of `cleanTweet` in 1 above to form a new column called $\\textbf{score}$ in `cleanTweet`.\n","\n","- Visualize The $\\textbf{score}$ column using piechart and barchart\n","\n","<h5>Now we want to build a classification model on the clean tweet following the steps below:</h5>\n","\n","* Remove rows from `cleanTweet` where $\\textbf{polarity}$ $= 0$ (i.e where $\\textbf{score}$ = Neutral) and reset the frame index.\n","* Construct a column $\\textbf{scoremap}$ Use the mapping {'positive':1, 'negative':0} on the $\\textbf{score}$ column\n","* Create feature and target variables `(X,y)` from $\\textbf{clean-text}$ and $\\textbf{scoremap}$ columns respectively.\n","* Use `train_test_split` function to construct `(X_train, y_train)` and `(X_test, y_test)` from `(X,y)`\n","\n","* Build an `SGDClassifier` model from the vectorize train text data. Use `CountVectorizer()` with a $\\textit{trigram}$ parameter.\n","\n","* Evaluate your model on the test data.\n"]},{"source":["<h3>Extract tweets dataframe<h3>"],"cell_type":"markdown","metadata":{}},{"cell_type":"code","metadata":{"id":"85WxmGNGDcBY"},"source":["import extract_dataframe as exdf \n","\n","_, tweet_list = exdf.read_json(\"./data/covid19.json\")\n","tweets_df_extractor = exdf.TweetDfExtractor(tweet_list)\n","tweets_df = tweets_df_extractor.get_tweet_df()\n","tweets_df"],"execution_count":1,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                          created_at  \\\n","0     Fri Jun 18 17:55:49 +0000 2021   \n","1     Fri Jun 18 17:55:59 +0000 2021   \n","2     Fri Jun 18 17:56:07 +0000 2021   \n","3     Fri Jun 18 17:56:10 +0000 2021   \n","4     Fri Jun 18 17:56:20 +0000 2021   \n","...                              ...   \n","6527  Sat Jun 19 07:41:15 +0000 2021   \n","6528  Sat Jun 19 07:41:26 +0000 2021   \n","6529  Sat Jun 19 07:41:31 +0000 2021   \n","6530  Sat Jun 19 07:41:45 +0000 2021   \n","6531  Sat Jun 19 07:41:54 +0000 2021   \n","\n","                                                 source  \\\n","0     <a href=\"http://twitter.com/download/iphone\" r...   \n","1     <a href=\"https://mobile.twitter.com\" rel=\"nofo...   \n","2     <a href=\"http://twitter.com/download/iphone\" r...   \n","3     <a href=\"https://mobile.twitter.com\" rel=\"nofo...   \n","4     <a href=\"http://twitter.com/download/android\" ...   \n","...                                                 ...   \n","6527  <a href=\"http://twitter.com/download/android\" ...   \n","6528  <a href=\"http://twitter.com/download/android\" ...   \n","6529  <a href=\"http://twitter.com/download/iphone\" r...   \n","6530  <a href=\"http://twitter.com/download/iphone\" r...   \n","6531  <a href=\"https://mobile.twitter.com\" rel=\"nofo...   \n","\n","                                          original_text  polarity  \\\n","0     RT @TelGlobalHealth: 🚨Africa is \"in the midst ...  0.000000   \n","1     RT @globalhlthtwit: Dr Moeti is head of WHO in...  0.133333   \n","2     RT @NHSRDForum: Thank you @research2note for c...  0.316667   \n","3     RT @HighWireTalk: Former Pfizer VP and Virolog...  0.166667   \n","4     RT @PeterHotez: I think it’s important that we...  0.300000   \n","...                                                 ...       ...   \n","6527  RT @Givenkazeni: Zweli please just release the...  0.000000   \n","6528  RT @HighWireTalk: Former Pfizer VP and Virolog...  0.166667   \n","6529  @Jenfeds73 @DcrInYYC Respectfully, veterinaria...  0.281250   \n","6530  RT @WHOAFRO: \"Africa needs millions more doses...  0.166667   \n","6531  RT @shawajason: Liars. You tried to load off y...  0.000000   \n","\n","      subjectivity lang favorite_count retweet_count original_author  \\\n","0         0.000000   en           None          None     ketuesriche   \n","1         0.455556   en           None          None        Grid1949   \n","2         0.483333   en           None          None   LeeTomlinson8   \n","3         0.166667   en           None          None         RIPNY08   \n","4         0.766667   en           None          None          pash22   \n","...            ...  ...            ...           ...             ...   \n","6527      0.400000   en           None          None    Mthatos_Vivi   \n","6528      0.166667   en           None          None     wayno_af007   \n","6529      0.506250   en           None          None    dublonothing   \n","6530      0.166667   en           None          None    DrAmirKhanGP   \n","6531      0.000000   en           None          None      jepigepas_   \n","\n","      followers_count  friends_count possibly_sensitive  \\\n","0                 551            351               None   \n","1                  66             92               None   \n","2                1195           1176               None   \n","3                2666           2704               None   \n","4               28250          30819               None   \n","...               ...            ...                ...   \n","6527              447           1089               None   \n","6528             2224           2739               None   \n","6529             3000           4709               None   \n","6530           135163           1284               None   \n","6531              160            712               None   \n","\n","                                               hashtags  \\\n","0                                                    []   \n","1                                                    []   \n","2     [{'text': 'red4research', 'indices': [103, 116]}]   \n","3                                                    []   \n","4                                                    []   \n","...                                                 ...   \n","6527                                                 []   \n","6528                                                 []   \n","6529                                                 []   \n","6530       [{'text': 'COVID19', 'indices': [120, 128]}]   \n","6531                                                 []   \n","\n","                                          user_mentions  \\\n","0     [{'screen_name': 'TelGlobalHealth', 'name': 'T...   \n","1     [{'screen_name': 'globalhlthtwit', 'name': 'An...   \n","2     [{'screen_name': 'NHSRDForum', 'name': 'NHS R&...   \n","3     [{'screen_name': 'HighWireTalk', 'name': 'The ...   \n","4     [{'screen_name': 'PeterHotez', 'name': 'Prof P...   \n","...                                                 ...   \n","6527  [{'screen_name': 'Givenkazeni', 'name': 'le’Gi...   \n","6528  [{'screen_name': 'HighWireTalk', 'name': 'The ...   \n","6529  [{'screen_name': 'Jenfeds73', 'name': 'Bubs 🇨🇦...   \n","6530  [{'screen_name': 'WHOAFRO', 'name': 'WHO Afric...   \n","6531  [{'screen_name': 'shawajason', 'name': 'J. Sha...   \n","\n","                         place  \n","0                         Mass  \n","1          Edinburgh, Scotland  \n","2                         None  \n","3                         None  \n","4               United Kingdom  \n","...                        ...  \n","6527                      None  \n","6528              The boro, MA  \n","6529           Los Angeles, CA  \n","6530  Yorkshire and The Humber  \n","6531                      None  \n","\n","[6532 rows x 15 columns]"],"text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>created_at</th>\n      <th>source</th>\n      <th>original_text</th>\n      <th>polarity</th>\n      <th>subjectivity</th>\n      <th>lang</th>\n      <th>favorite_count</th>\n      <th>retweet_count</th>\n      <th>original_author</th>\n      <th>followers_count</th>\n      <th>friends_count</th>\n      <th>possibly_sensitive</th>\n      <th>hashtags</th>\n      <th>user_mentions</th>\n      <th>place</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Fri Jun 18 17:55:49 +0000 2021</td>\n      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n      <td>RT @TelGlobalHealth: 🚨Africa is \"in the midst ...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>en</td>\n      <td>None</td>\n      <td>None</td>\n      <td>ketuesriche</td>\n      <td>551</td>\n      <td>351</td>\n      <td>None</td>\n      <td>[]</td>\n      <td>[{'screen_name': 'TelGlobalHealth', 'name': 'T...</td>\n      <td>Mass</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Fri Jun 18 17:55:59 +0000 2021</td>\n      <td>&lt;a href=\"https://mobile.twitter.com\" rel=\"nofo...</td>\n      <td>RT @globalhlthtwit: Dr Moeti is head of WHO in...</td>\n      <td>0.133333</td>\n      <td>0.455556</td>\n      <td>en</td>\n      <td>None</td>\n      <td>None</td>\n      <td>Grid1949</td>\n      <td>66</td>\n      <td>92</td>\n      <td>None</td>\n      <td>[]</td>\n      <td>[{'screen_name': 'globalhlthtwit', 'name': 'An...</td>\n      <td>Edinburgh, Scotland</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Fri Jun 18 17:56:07 +0000 2021</td>\n      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n      <td>RT @NHSRDForum: Thank you @research2note for c...</td>\n      <td>0.316667</td>\n      <td>0.483333</td>\n      <td>en</td>\n      <td>None</td>\n      <td>None</td>\n      <td>LeeTomlinson8</td>\n      <td>1195</td>\n      <td>1176</td>\n      <td>None</td>\n      <td>[{'text': 'red4research', 'indices': [103, 116]}]</td>\n      <td>[{'screen_name': 'NHSRDForum', 'name': 'NHS R&amp;...</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Fri Jun 18 17:56:10 +0000 2021</td>\n      <td>&lt;a href=\"https://mobile.twitter.com\" rel=\"nofo...</td>\n      <td>RT @HighWireTalk: Former Pfizer VP and Virolog...</td>\n      <td>0.166667</td>\n      <td>0.166667</td>\n      <td>en</td>\n      <td>None</td>\n      <td>None</td>\n      <td>RIPNY08</td>\n      <td>2666</td>\n      <td>2704</td>\n      <td>None</td>\n      <td>[]</td>\n      <td>[{'screen_name': 'HighWireTalk', 'name': 'The ...</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Fri Jun 18 17:56:20 +0000 2021</td>\n      <td>&lt;a href=\"http://twitter.com/download/android\" ...</td>\n      <td>RT @PeterHotez: I think it’s important that we...</td>\n      <td>0.300000</td>\n      <td>0.766667</td>\n      <td>en</td>\n      <td>None</td>\n      <td>None</td>\n      <td>pash22</td>\n      <td>28250</td>\n      <td>30819</td>\n      <td>None</td>\n      <td>[]</td>\n      <td>[{'screen_name': 'PeterHotez', 'name': 'Prof P...</td>\n      <td>United Kingdom</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>6527</th>\n      <td>Sat Jun 19 07:41:15 +0000 2021</td>\n      <td>&lt;a href=\"http://twitter.com/download/android\" ...</td>\n      <td>RT @Givenkazeni: Zweli please just release the...</td>\n      <td>0.000000</td>\n      <td>0.400000</td>\n      <td>en</td>\n      <td>None</td>\n      <td>None</td>\n      <td>Mthatos_Vivi</td>\n      <td>447</td>\n      <td>1089</td>\n      <td>None</td>\n      <td>[]</td>\n      <td>[{'screen_name': 'Givenkazeni', 'name': 'le’Gi...</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>6528</th>\n      <td>Sat Jun 19 07:41:26 +0000 2021</td>\n      <td>&lt;a href=\"http://twitter.com/download/android\" ...</td>\n      <td>RT @HighWireTalk: Former Pfizer VP and Virolog...</td>\n      <td>0.166667</td>\n      <td>0.166667</td>\n      <td>en</td>\n      <td>None</td>\n      <td>None</td>\n      <td>wayno_af007</td>\n      <td>2224</td>\n      <td>2739</td>\n      <td>None</td>\n      <td>[]</td>\n      <td>[{'screen_name': 'HighWireTalk', 'name': 'The ...</td>\n      <td>The boro, MA</td>\n    </tr>\n    <tr>\n      <th>6529</th>\n      <td>Sat Jun 19 07:41:31 +0000 2021</td>\n      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n      <td>@Jenfeds73 @DcrInYYC Respectfully, veterinaria...</td>\n      <td>0.281250</td>\n      <td>0.506250</td>\n      <td>en</td>\n      <td>None</td>\n      <td>None</td>\n      <td>dublonothing</td>\n      <td>3000</td>\n      <td>4709</td>\n      <td>None</td>\n      <td>[]</td>\n      <td>[{'screen_name': 'Jenfeds73', 'name': 'Bubs 🇨🇦...</td>\n      <td>Los Angeles, CA</td>\n    </tr>\n    <tr>\n      <th>6530</th>\n      <td>Sat Jun 19 07:41:45 +0000 2021</td>\n      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n      <td>RT @WHOAFRO: \"Africa needs millions more doses...</td>\n      <td>0.166667</td>\n      <td>0.166667</td>\n      <td>en</td>\n      <td>None</td>\n      <td>None</td>\n      <td>DrAmirKhanGP</td>\n      <td>135163</td>\n      <td>1284</td>\n      <td>None</td>\n      <td>[{'text': 'COVID19', 'indices': [120, 128]}]</td>\n      <td>[{'screen_name': 'WHOAFRO', 'name': 'WHO Afric...</td>\n      <td>Yorkshire and The Humber</td>\n    </tr>\n    <tr>\n      <th>6531</th>\n      <td>Sat Jun 19 07:41:54 +0000 2021</td>\n      <td>&lt;a href=\"https://mobile.twitter.com\" rel=\"nofo...</td>\n      <td>RT @shawajason: Liars. You tried to load off y...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>en</td>\n      <td>None</td>\n      <td>None</td>\n      <td>jepigepas_</td>\n      <td>160</td>\n      <td>712</td>\n      <td>None</td>\n      <td>[]</td>\n      <td>[{'screen_name': 'shawajason', 'name': 'J. Sha...</td>\n      <td>None</td>\n    </tr>\n  </tbody>\n</table>\n<p>6532 rows × 15 columns</p>\n</div>"},"metadata":{},"execution_count":1}]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}]}