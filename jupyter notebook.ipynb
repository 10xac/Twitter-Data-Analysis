{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled4.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "eGRKbj_noIwX"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import json\n",
        "\n",
        "from wordcloud import WordCloud,STOPWORDS\n",
        "import re, nltk\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn import model_selection, naive_bayes, svm\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score,confusion_matrix,classification_report\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "import pickle\n",
        "\n",
        "pd.set_option('display.max_colwidth', -1)\n",
        " \n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Deep Learning Model - Keras\n",
        "from keras.models import Model\n",
        "from keras.models import Sequential\n",
        "\n",
        "# Deep Learning Model - Keras - CNN\n",
        "\n",
        "from keras.layers import MaxPooling2D, GlobalMaxPooling2D, GlobalAveragePooling2D\n",
        "\n",
        "from keras.layers import MaxPooling3D, GlobalMaxPooling3D, GlobalAveragePooling3D\n",
        "\n",
        "# Deep Learning Model - Keras - RNN\n",
        "from keras.layers import Embedding, LSTM, Bidirectional\n",
        "\n",
        "# Deep Learning Model - Keras - General\n",
        "from keras.layers import Input, Add, concatenate, Dense, Activation, BatchNormalization, Dropout, Flatten\n",
        "\n",
        "# Deep Learing Preprocessing - Keras\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing import sequence\n",
        "\n",
        "from sklearn import preprocessing\n",
        "from sklearn.utils import class_weight as cw\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import LabelEncoder\n"
      ],
      "metadata": {
        "id": "YIyOip3hvlTS"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Read in data\n",
        "df = pd.read_csv(\"C:\\Users\\HP15NOTEBOOK\\Downloads\\Economic_Twitter_Data (1).zip\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 135
        },
        "id": "SlOGQPcjvmws",
        "outputId": "004972ef-b3f3-455b-915c-2b26d187fc04"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-11-c50fe401da2a>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    df = pd.read_csv(\"C:\\Users\\HP15NOTEBOOK\\Downloads\\Economic_Twitter_Data (1).zip\")\u001b[0m\n\u001b[0m                    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m (unicode error) 'unicodeescape' codec can't decode bytes in position 2-3: truncated \\UXXXXXXXX escape\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Missing info check\n",
        "data.isnull().sum()"
      ],
      "metadata": {
        "id": "HC4U5Y7YyJ77"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#checking data\n",
        "data.head(5)"
      ],
      "metadata": {
        "id": "Tz5a4FXXyPgD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preprocessing Data"
      ],
      "metadata": {
        "id": "pnNdE173zSn0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Q9-LYjpozTou"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "0Tjh7jVTzTzu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Modeling"
      ],
      "metadata": {
        "id": "xYYO0EKTzYiD"
      }
    }
  ]
}