{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.4"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.4 64-bit"
  },
  "interpreter": {
   "hash": "2db524e06e9f5f4ffedc911c917cb75e12dbc923643829bf417064a77eb14d37"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "<h1>Modelling</h1>"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "<h3>Importing Model Ready Data</h3>"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   sentiment lang      hashtags  \\\n",
       "0          1   en                 \n",
       "1          1   en                 \n",
       "2          1   en  red4research   \n",
       "3          1   en                 \n",
       "4          1   en                 \n",
       "\n",
       "                                          clean_text  \n",
       "0  rt telglobalhealth africa is in the midst of a...  \n",
       "1  rt globalhlthtwit dr moeti is head of who in a...  \n",
       "2  rt nhsrdforum thank you research note for crea...  \n",
       "3  rt highwiretalk former pfizer vp and virologis...  \n",
       "4  rt peterhotez i think it s important that we d...  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sentiment</th>\n      <th>lang</th>\n      <th>hashtags</th>\n      <th>clean_text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>en</td>\n      <td></td>\n      <td>rt telglobalhealth africa is in the midst of a...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>en</td>\n      <td></td>\n      <td>rt globalhlthtwit dr moeti is head of who in a...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>en</td>\n      <td>red4research</td>\n      <td>rt nhsrdforum thank you research note for crea...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>en</td>\n      <td></td>\n      <td>rt highwiretalk former pfizer vp and virologis...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>en</td>\n      <td></td>\n      <td>rt peterhotez i think it s important that we d...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 129
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "model_tweets = pd.read_csv('../data/model_ready_data.csv')\n",
    "model_tweets = model_tweets.fillna(\"\")\n",
    "model_tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(6417, 4)"
      ]
     },
     "metadata": {},
     "execution_count": 130
    }
   ],
   "source": [
    "model_tweets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4492 1925\n",
    "sentiment_analysis_tweet_data = model_tweets.copy(deep=True)\n",
    "sentiment_analysis_tweet_data.drop(sentiment_analysis_tweet_data[sentiment_analysis_tweet_data['sentiment'] == -1].index, inplace=True)\n",
    "sentiment_analysis_tweet_data.reset_index(drop=True, inplace=True)\n",
    "tweet_train = sentiment_analysis_tweet_data.iloc[:4492,]\n",
    "tweet_test = sentiment_analysis_tweet_data.iloc[4493:,]"
   ]
  },
  {
   "source": [
    "<h3>Sentiment Analysis</h3>"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from joblib import dump, load # used for saving and loading sklearn objects\n",
    "from scipy.sparse import save_npz, load_npz # used for saving and loading sparse matrices\n",
    "from sklearn.decomposition import NMF, LatentDirichletAllocation"
   ]
  },
  {
   "source": [
    "#### Unigram Counts"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "CountVectorizer()"
      ]
     },
     "metadata": {},
     "execution_count": 158
    }
   ],
   "source": [
    "unigram_vectorizer = CountVectorizer(ngram_range=(1, 1))\n",
    "unigram_vectorizer.fit(tweet_train['clean_text'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_unigram = unigram_vectorizer.transform(tweet_train['clean_text'].values)"
   ]
  },
  {
   "source": [
    "#### Unigram Tf-Idf"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "TfidfTransformer()"
      ]
     },
     "metadata": {},
     "execution_count": 160
    }
   ],
   "source": [
    "unigram_tf_idf_transformer = TfidfTransformer()\n",
    "unigram_tf_idf_transformer.fit(X_train_unigram)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_unigram_tf_idf = unigram_tf_idf_transformer.transform(X_train_unigram)"
   ]
  },
  {
   "source": [
    "#### Bigram Counts"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "CountVectorizer(ngram_range=(1, 2))"
      ]
     },
     "metadata": {},
     "execution_count": 162
    }
   ],
   "source": [
    "bigram_vectorizer = CountVectorizer(ngram_range=(1, 2))\n",
    "bigram_vectorizer.fit(tweet_train['clean_text'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_bigram = bigram_vectorizer.transform(tweet_train['clean_text'].values)"
   ]
  },
  {
   "source": [
    "#### Bigram Tf-Idf"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "TfidfTransformer()"
      ]
     },
     "metadata": {},
     "execution_count": 164
    }
   ],
   "source": [
    "bigram_tf_idf_transformer = TfidfTransformer()\n",
    "bigram_tf_idf_transformer.fit(X_train_bigram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_bigram_tf_idf = bigram_tf_idf_transformer.transform(X_train_bigram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.sparse import csr_matrix\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_show_scores(X: csr_matrix, y: np.array, title: str) -> None:\n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "        X, y,train_size=0.75, stratify=y\n",
    "    )\n",
    "\n",
    "    clf = SGDClassifier()\n",
    "    clf.fit(X_train, y_train)\n",
    "    train_score = clf.score(X_train, y_train)\n",
    "    valid_score = clf.score(X_valid, y_valid)\n",
    "\n",
    "    global_vars = globals()\n",
    "    if(valid_score > global_vars['best_score']):\n",
    "        global_vars['best_model'] = clf\n",
    "        global_vars['best_model_name'] = title\n",
    "        global_vars['best_score'] = valid_score\n",
    "\n",
    "    print(f'{title}\\nTrain score: {round(train_score, 2)} ; Validation score: {round(valid_score, 2)}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 1, 1, 1], dtype=int64)"
      ]
     },
     "metadata": {},
     "execution_count": 168
    }
   ],
   "source": [
    "y_train = tweet_train['sentiment'].values\n",
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Unigram Counts\nTrain score: 1.0 ; Validation score: 0.98\n\nUnigram Tf-Idf\nTrain score: 1.0 ; Validation score: 0.98\n\nBigram Counts\nTrain score: 1.0 ; Validation score: 0.98\n\nBigram Tf-Idf\nTrain score: 1.0 ; Validation score: 0.98\n\n"
     ]
    }
   ],
   "source": [
    "best_model = \"\"\n",
    "best_model_name = \"\"\n",
    "best_score = 0\n",
    "\n",
    "train_and_show_scores(X_train_unigram, y_train, 'Unigram Counts')\n",
    "train_and_show_scores(X_train_unigram_tf_idf, y_train, 'Unigram Tf-Idf')\n",
    "train_and_show_scores(X_train_bigram, y_train, 'Bigram Counts')\n",
    "train_and_show_scores(X_train_bigram_tf_idf, y_train, 'Bigram Tf-Idf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "The best Model is Unigram Tf-Idf with a Validation score of: 0.98\n"
     ]
    }
   ],
   "source": [
    "print(f'The best Model is {best_model_name} with a Validation score of: {round(best_score, 2)}')"
   ]
  },
  {
   "source": [
    "Testing"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_test_using_model(best_model: SGDClassifier, model_type: str):\n",
    "    unigram_vectorizer = CountVectorizer(ngram_range=(1, 1))\n",
    "    unigram_vectorizer.fit(tweet_test['clean_text'].values)\n",
    "    X_test_unigram = unigram_vectorizer.transform(tweet_test['clean_text'].values)\n",
    "\n",
    "    bigram_vectorizer = CountVectorizer(ngram_range=(1, 2))\n",
    "    bigram_vectorizer.fit(tweet_test['clean_text'].values)\n",
    "    X_test_bigram = bigram_vectorizer.transform(tweet_test['clean_text'].values)\n",
    "\n",
    "    y_test = tweet_test['sentiment'].values\n",
    "\n",
    "    if(model_type == \"Unigram Counts\"):\n",
    "        X_test = X_test_unigram\n",
    "\n",
    "    elif(model_type == \"Unigram Tf-Idf\"):\n",
    "        unigram_tf_idf_transformer = TfidfTransformer()\n",
    "        unigram_tf_idf_transformer.fit(X_test_unigram)\n",
    "        X_test_unigram_tf_idf = unigram_tf_idf_transformer.transform(X_test_unigram)\n",
    "\n",
    "        X_test = X_test_unigram_tf_idf\n",
    "\n",
    "    elif(model_type == \"Bigram Counts\"):\n",
    "        X_test = X_test_bigram\n",
    "\n",
    "    else:\n",
    "        bigram_tf_idf_transformer = TfidfTransformer()\n",
    "        bigram_tf_idf_transformer.fit(X_test_bigram)\n",
    "\n",
    "        X_test_bigram_tf_idf = bigram_tf_idf_transformer.transform(X_test_bigram)\n",
    "        X_test = X_test_bigram_tf_idf\n",
    "\n",
    "   \n",
    "    return best_model.score(X_test,y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "empty vocabulary; perhaps the documents only contain stop words",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-177-10483ae3d987>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# type(tweet_test['clean_text'].values)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mrun_test_using_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbest_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbest_model_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-176-6d660242c87c>\u001b[0m in \u001b[0;36mrun_test_using_model\u001b[1;34m(best_model, model_type)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mrun_test_using_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbest_model\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mSGDClassifier\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel_type\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0munigram_vectorizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCountVectorizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mngram_range\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0munigram_vectorizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtweet_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'clean_text'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0mX_test_unigram\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0munigram_vectorizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtweet_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'clean_text'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Python38\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, raw_documents, y)\u001b[0m\n\u001b[0;32m   1168\u001b[0m         \"\"\"\n\u001b[0;32m   1169\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_warn_for_unused_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1170\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mraw_documents\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1171\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1172\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Python38\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36mfit_transform\u001b[1;34m(self, raw_documents, y)\u001b[0m\n\u001b[0;32m   1201\u001b[0m         \u001b[0mmax_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_features\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1202\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1203\u001b[1;33m         vocabulary, X = self._count_vocab(raw_documents,\n\u001b[0m\u001b[0;32m   1204\u001b[0m                                           self.fixed_vocabulary_)\n\u001b[0;32m   1205\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Python38\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36m_count_vocab\u001b[1;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[0;32m   1132\u001b[0m             \u001b[0mvocabulary\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvocabulary\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1133\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mvocabulary\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1134\u001b[1;33m                 raise ValueError(\"empty vocabulary; perhaps the documents only\"\n\u001b[0m\u001b[0;32m   1135\u001b[0m                                  \" contain stop words\")\n\u001b[0;32m   1136\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: empty vocabulary; perhaps the documents only contain stop words"
     ]
    }
   ],
   "source": [
    "# type(tweet_test['clean_text'].values)\n",
    "run_test_using_model(best_model, best_model_name)"
   ]
  },
  {
   "source": [
    "Saving generated Topic LDA Model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(best_model, '../trained_models/sentimentSGDmodel')\n",
    "# then reload it with\n",
    "# lda_model = joblib.load('lda_model.jl')"
   ]
  },
  {
   "source": [
    "<h3>Topic Modelling</h3>"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[nltk_data] Downloading package stopwords to\n[nltk_data]     C:\\Users\\milky\\AppData\\Roaming\\nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "execution_count": 110
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as  pd\n",
    "from pprint import pprint\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "import spacy\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim_models\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib\n",
    "%matplotlib inline"
   ]
  },
  {
   "source": [
    "Stopwords Preparation"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NLTK Stop words\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "stop_words.extend(['from', 'subject', 're', 'edu', 'use'])"
   ]
  },
  {
   "source": [
    "Loading Dataset"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "      sentiment lang      hashtags  \\\n",
       "0             1   en                 \n",
       "1             1   en                 \n",
       "2             1   en  red4research   \n",
       "3             1   en                 \n",
       "4             1   en                 \n",
       "...         ...  ...           ...   \n",
       "6412         -1   en                 \n",
       "6413         -1   en       covid19   \n",
       "6414         -1   en                 \n",
       "6415         -1   en       covid19   \n",
       "6416          1   en       covid19   \n",
       "\n",
       "                                             clean_text  \n",
       "0     rt telglobalhealth africa is in the midst of a...  \n",
       "1     rt globalhlthtwit dr moeti is head of who in a...  \n",
       "2     rt nhsrdforum thank you research note for crea...  \n",
       "3     rt highwiretalk former pfizer vp and virologis...  \n",
       "4     rt peterhotez i think it s important that we d...  \n",
       "...                                                 ...  \n",
       "6412  pin code kamala nehru pmcgvaccines covaxin min...  \n",
       "6413  minute interview with the inventor of mrna vac...  \n",
       "6414  rt shawajason liars you tried to load off your...  \n",
       "6415  rt kalainh as of june th t amp t has administe...  \n",
       "6416  rt whoafro africa needs millions more doses he...  \n",
       "\n",
       "[6417 rows x 4 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sentiment</th>\n      <th>lang</th>\n      <th>hashtags</th>\n      <th>clean_text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>en</td>\n      <td></td>\n      <td>rt telglobalhealth africa is in the midst of a...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>en</td>\n      <td></td>\n      <td>rt globalhlthtwit dr moeti is head of who in a...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>en</td>\n      <td>red4research</td>\n      <td>rt nhsrdforum thank you research note for crea...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>en</td>\n      <td></td>\n      <td>rt highwiretalk former pfizer vp and virologis...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>en</td>\n      <td></td>\n      <td>rt peterhotez i think it s important that we d...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>6412</th>\n      <td>-1</td>\n      <td>en</td>\n      <td></td>\n      <td>pin code kamala nehru pmcgvaccines covaxin min...</td>\n    </tr>\n    <tr>\n      <th>6413</th>\n      <td>-1</td>\n      <td>en</td>\n      <td>covid19</td>\n      <td>minute interview with the inventor of mrna vac...</td>\n    </tr>\n    <tr>\n      <th>6414</th>\n      <td>-1</td>\n      <td>en</td>\n      <td></td>\n      <td>rt shawajason liars you tried to load off your...</td>\n    </tr>\n    <tr>\n      <th>6415</th>\n      <td>-1</td>\n      <td>en</td>\n      <td>covid19</td>\n      <td>rt kalainh as of june th t amp t has administe...</td>\n    </tr>\n    <tr>\n      <th>6416</th>\n      <td>1</td>\n      <td>en</td>\n      <td>covid19</td>\n      <td>rt whoafro africa needs millions more doses he...</td>\n    </tr>\n  </tbody>\n</table>\n<p>6417 rows × 4 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 113
    }
   ],
   "source": [
    "topic_model_data = model_tweets.copy(deep=True)\n",
    "topic_model_data"
   ]
  },
  {
   "source": [
    "Tokenizing words"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hastags_words_list():\n",
    "    hashtagList = []\n",
    "    for hashtags in topic_model_data.hashtags:\n",
    "        if(hashtags != \"\"):\n",
    "            hashtagList += hashtags.split(',')\n",
    "\n",
    "    return hashtagList\n",
    "\n",
    "hashtag = get_hastags_words_list()\n",
    "\n",
    "data = [word for sentence in topic_model_data.clean_text for word in sentence.split(' ')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['red4research', 'wecandothis', 'covid19', 'wecandothis', 'cuban']"
      ]
     },
     "metadata": {},
     "execution_count": 115
    }
   ],
   "source": [
    "hashtag[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['rt',\n",
       " 'telglobalhealth',\n",
       " 'africa',\n",
       " 'is',\n",
       " 'in',\n",
       " 'the',\n",
       " 'midst',\n",
       " 'of',\n",
       " 'a',\n",
       " 'full']"
      ]
     },
     "metadata": {},
     "execution_count": 116
    }
   ],
   "source": [
    "data[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['rt', 'telglobalhealth', 'africa', 'is', 'in']"
      ]
     },
     "metadata": {},
     "execution_count": 117
    }
   ],
   "source": [
    "data_words = data + hashtag\n",
    "data_words = [word for word in data_words if word != '']\n",
    "data_words[:5]"
   ]
  },
  {
   "source": [
    "Creating bigram and trigram models"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['r', 't']\n"
     ]
    }
   ],
   "source": [
    "# Build the bigram and trigram models\n",
    "bigram = gensim.models.Phrases(data_words, min_count=5, threshold=100) # higher threshold fewer phrases.\n",
    "trigram = gensim.models.Phrases(bigram[data_words], threshold=100)\n",
    "# Faster way to get a sentence clubbed as a trigram/bigram\n",
    "bigram_mod = gensim.models.phrases.Phraser(bigram)\n",
    "trigram_mod = gensim.models.phrases.Phraser(trigram)\n",
    "# See trigram example\n",
    "print(trigram_mod[bigram_mod[data_words[0]]])"
   ]
  },
  {
   "source": [
    "Removing Stopwords, making bigrams and lemmatization"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function for stopwords, bigrams, trigrams and lemmatization\n",
    "def remove_stopwords(texts):\n",
    "    return [[word for word in simple_preprocess(str(doc)) if word not in stop_words] for doc in texts]\n",
    "\n",
    "def make_bigrams(texts):\n",
    "    return [bigram_mod[doc] for doc in texts]\n",
    "\n",
    "def make_trigrams(texts):\n",
    "    return [trigram_mod[bigram_mod[doc]] for doc in texts]\n",
    "\n",
    "def lemmatization(texts, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV']):\n",
    "    texts_out = []\n",
    "    for sent in texts:\n",
    "        doc = nlp(\" \".join(sent)) \n",
    "        texts_out.append([token.lemma_ for token in doc if token.pos_ in allowed_postags])\n",
    "    return texts_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[]]\n"
     ]
    }
   ],
   "source": [
    "# Remove Stop Words\n",
    "data_words_nostops = remove_stopwords(data_words)\n",
    "\n",
    "# Form Bigrams\n",
    "data_words_bigrams = make_bigrams(data_words_nostops)\n",
    "\n",
    "# Initialize spacy 'en' model, keeping only tagger component (for efficiency)\n",
    "# python3 -m spacy download en\n",
    "nlp = spacy.load('en_core_web_sm', disable=['parser', 'ner'])\n",
    "\n",
    "# Do lemmatization keeping only noun, adj, vb, adv\n",
    "data_lemmatized = lemmatization(data_words_bigrams, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV'])\n",
    "\n",
    "print(data_lemmatized[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[['telglobalhealth'], ['africa'], ['midst'], ['full'], ['blow']]"
      ]
     },
     "metadata": {},
     "execution_count": 121
    }
   ],
   "source": [
    "data_lemmatized = [word for word in data_lemmatized if word != []]\n",
    "data_lemmatized[:5]"
   ]
  },
  {
   "source": [
    "Create Dictionary and Corpus needed for Topic Modeling"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "], [(64, 1)], [(7, 1)], [(765, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(441, 1)], [(64, 1)], [(64, 1)], [(844, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(7, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(374, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(278, 1)], [(7, 1)], [(844, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(720, 1)], [(441, 1)], [(64, 1)], [(64, 1)], [(194, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(1335, 1)], [(1335, 1)], [(64, 1)], [(2380, 1)], [(7, 1)], [(2381, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(2396, 1)], [(524, 1)], [(64, 1)], [(49, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(92, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(1176, 1)], [(177, 1)], [(1176, 1)], [(64, 1)], [(64, 1)], [(290, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(7, 1)], [(64, 1)], [(2483, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(65, 1)], [(64, 1)], [(64, 1)], [(290, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(1176, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(2483, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(2353, 1)], [(92, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(374, 1)], [(7, 1)], [(92, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(409, 1)], [(64, 1)], [(64, 1)], [(1726, 1)], [(64, 1)], [(2572, 1)], [(290, 1)], [(1573, 1)], [(64, 1)], [(64, 1)], [(1, 1)], [(64, 1)], [(374, 1)], [(64, 1)], [(64, 1)], [(2593, 1)], [(64, 1)], [(374, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(2042, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(1726, 1)], [(92, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(2632, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(177, 1)], [(1, 1)], [(177, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(49, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(7, 1)], [(64, 1)], [(374, 1)], [(720, 1)], [(2353, 1)], [(64, 1)], [(720, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(374, 1)], [(64, 1)], [(64, 1)], [(278, 1)], [(7, 1)], [(374, 1)], [(64, 1)], [(374, 1)], [(64, 1)], [(92, 1)], [(64, 1)], [(64, 1)], [(1, 1)], [(374, 1)], [(278, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(92, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(374, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(7, 1)], [(65, 1)], [(720, 1)], [(64, 1)], [(7, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(1, 1)], [(64, 1)], [(1, 1)], [(1, 1)], [(64, 1)], [(1, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(7, 1)], [(64, 1)], [(1, 1)], [(1, 1)], [(1, 1)], [(64, 1)], [(2796, 1)], [(64, 1)], [(64, 1)], [(1192, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(130, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(1, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(7, 1)], [(278, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(7, 1)], [(64, 1)], [(64, 1)], [(278, 1)], [(64, 1)], [(194, 1)], [(290, 1)], [(2877, 1)], [(2880, 1)], [(64, 1)], [(64, 1)], [(374, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(1905, 1)], [(64, 1)], [(1905, 1)], [(64, 1)], [(64, 1)], [(374, 1)], [(64, 1)], [(177, 1)], [(64, 1)], [(64, 1)], [(1, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(844, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(37, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(374, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(2931, 1)], [(64, 1)], [(2933, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(1, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(276, 1)], [(64, 1)], [(64, 1)], [(1905, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(7, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(177, 1)], [(290, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(1258, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(374, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(4683, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(2989, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(3015, 1)], [(64, 1)], [(374, 1)], [(64, 1)], [(64, 1)], [(374, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(629, 1)], [(64, 1)], [(629, 1)], [(64, 1)], [(64, 1)], [(374, 1)], [(24, 1), (33, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(278, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(996, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(65, 1)], [(1, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(92, 1)], [(64, 1)], [(4684, 1)], [(629, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(3071, 1)], [(905, 1)], [(64, 1)], [(64, 1)], [(1984, 1)], [(278, 1)], [(278, 1)], [(64, 1)], [(374, 1)], [(64, 1)], [(374, 1)], [(374, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(3101, 1)], [(64, 1)], [(92, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(2931, 1)], [(2931, 1)], [(64, 1)], [(64, 1)], [(591, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(2931, 1)], [(64, 1)], [(2931, 1)], [(374, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(905, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(92, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(3162, 1)], [(374, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(3170, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(374, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(1, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(3218, 1)], [(65, 1)], [(1, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(3237, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(3250, 1)], [(64, 1)], [(64, 1)], [(3250, 1)], [(64, 1)], [(64, 1)], [(374, 1)], [(374, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(177, 1)], [(64, 1)], [(177, 1)], [(64, 1)], [(64, 1)], [(177, 1)], [(64, 1)], [(374, 1)], [(3276, 1)], [(64, 1)], [(414, 1)], [(3279, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(3282, 1)], [(629, 1)], [(64, 1)], [(7, 1)], [(64, 1)], [(7, 1)], [(65, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(3282, 1)], [(64, 1)], [(3282, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(2009, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(3318, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(65, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(3218, 1)], [(49, 1)], [(64, 1)], [(3338, 1)], [(1590, 1)], [(3338, 1)], [(64, 1)], [(64, 1)], [(3347, 1)], [(64, 1)], [(64, 1)], [(1491, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(92, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(905, 1)], [(64, 1)], [(64, 1)], [(374, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(3386, 1)], [(64, 1)], [(365, 1)], [(65, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(1268, 1)], [(3406, 1)], [(3406, 1)], [(3410, 1)], [(64, 1)], [(64, 1)], [(177, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(65, 1)], [(2009, 1)], [(2009, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(1176, 1)], [(2096, 1)], [(4685, 1)], [(2096, 1)], [(64, 1)], [(64, 1)], [(3406, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(92, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(3406, 1)], [(3406, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(92, 1)], [(64, 1)], [(64, 1)], [(3276, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(1446, 1)], [(177, 1)], [(177, 1)], [(64, 1)], [(365, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(3479, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(3237, 1)], [(1946, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(177, 1)], [(1590, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(2880, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(3539, 1)], [(64, 1)], [(64, 1)], [(1446, 1)], [(64, 1)], [(374, 1)], [(374, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(65, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(3548, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(3554, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(374, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(65, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(2880, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(3600, 1)], [(2880, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(278, 1)], [(64, 1)], [(3609, 1)], [(64, 1)], [(64, 1)], [(3563, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(996, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(441, 1)], [(4686, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(3641, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(3652, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(278, 1)], [(65, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(278, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(3282, 1)], [(64, 1)], [(3712, 1)], [(593, 1)], [(64, 1)], [(3406, 1)], [(64, 1)], [(64, 1)], [(1590, 1)], [(1, 1)], [(64, 1)], [(64, 1)], [(130, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(2931, 1)], [(64, 1)], [(64, 1)], [(3738, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(3738, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(1928, 1)], [(177, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(3778, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(3788, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(92, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(3797, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(1451, 1)], [(3162, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(1075, 1)], [(64, 1)], [(1075, 1)], [(1075, 1)], [(1075, 1)], [(1075, 1)], [(1075, 1)], [(1075, 1)], [(1075, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(3859, 1)], [(64, 1)], [(7, 1)], [(3867, 1)], [(64, 1)], [(177, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(593, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(374, 1)], [(64, 1)], [(374, 1)], [(64, 1)], [(64, 1)], [(374, 1)], [(64, 1)], [(3903, 1)], [(64, 1)], [(374, 1)], [(1733, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(374, 1)], [(290, 1)], [(7, 1)], [(64, 1)], [(7, 1)], [(64, 1)], [(593, 1)], [(64, 1)], [(7, 1)], [(593, 1)], [(593, 1)], [(64, 1)], [(64, 1)], [(7, 1)], [(593, 1)], [(7, 1)], [(64, 1)], [(64, 1)], [(7, 1)], [(7, 1)], [(7, 1)], [(64, 1)], [(7, 1)], [(374, 1)], [(290, 1)], [(64, 1)], [(290, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(7, 1)], [(64, 1)], [(7, 1)], [(7, 1)], [(64, 1)], [(7, 1)], [(64, 1)], [(374, 1)], [(64, 1)], [(64, 1)], [(7, 1)], [(49, 1)], [(374, 1)], [(64, 1)], [(7, 1)], [(7, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(7, 1)], [(64, 1)], [(7, 1)], [(7, 1)], [(3972, 1)], [(65, 1)], [(64, 1)], [(64, 1)], [(7, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(7, 1)], [(64, 1)], [(7, 1)], [(278, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(7, 1)], [(194, 1)], [(64, 1)], [(278, 1)], [(3983, 1)], [(7, 1)], [(720, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(65, 1)], [(64, 1)], [(92, 1)], [(3972, 1)], [(64, 1)], [(7, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(49, 1)], [(762, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(7, 1)], [(3983, 1)], [(64, 1)], [(64, 1)], [(49, 1)], [(64, 1)], [(64, 1)], [(4003, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(278, 1)], [(3162, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(7, 1)], [(389, 1)], [(389, 1)], [(64, 1)], [(593, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(278, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(4048, 1)], [(64, 1)], [(7, 1)], [(762, 1)], [(1, 1)], [(64, 1)], [(4048, 1)], [(278, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(278, 1)], [(278, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(3282, 1)], [(64, 1)], [(64, 1)], [(3282, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(398, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(619, 1)], [(64, 1)], [(64, 1)], [(619, 1)], [(64, 1)], [(64, 1)], [(374, 1)], [(619, 1)], [(619, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(4114, 1)], [(64, 1)], [(64, 1)], [(7, 1)], [(64, 1)], [(64, 1)], [(2120, 1)], [(4133, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(905, 1)], [(64, 1)], [(64, 1)], [(4141, 1)], [(64, 1)], [(64, 1)], [(290, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(1268, 1)], [(1647, 1)], [(4165, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(4170, 1)], [(7, 1)], [(64, 1)], [(7, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(1, 1)], [(7, 1)], [(7, 1)], [(7, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(7, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(7, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(7, 1)], [(64, 1)], [(7, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(374, 1)], [(2120, 1)], [(64, 1)], [(7, 1)], [(64, 1)], [(4048, 1)], [(4048, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(996, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(290, 1)], [(64, 1)], [(4048, 1)], [(64, 1)], [(64, 1)], [(7, 1)], [(4048, 1)], [(64, 1)], [(64, 1)], [(3972, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(4048, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(7, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(3972, 1)], [(64, 1)], [(64, 1)], [(374, 1)], [(64, 1)], [(374, 1)], [(7, 1)], [(64, 1)], [(64, 1)], [(905, 1)], [(3641, 1)], [(64, 1)], [(4048, 1)], [(4048, 1)], [(278, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(720, 1)], [(720, 1)], [(720, 1)], [(64, 1)], [(720, 1)], [(64, 1)], [(278, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(4279, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(3972, 1)], [(64, 1)], [(149, 1)], [(1, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(720, 1)], [(7, 1)], [(64, 1)], [(64, 1)], [(3600, 1)], [(64, 1)], [(374, 1)], [(2009, 1)], [(194, 1)], [(64, 1)], [(4048, 1)], [(4333, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(1881, 1)], [(64, 1)], [(374, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1), (177, 1)], [(64, 1)], [(441, 1)], [(64, 1)], [(7, 1)], [(64, 1)], [(4687, 1)], [(1, 1)], [(64, 1)], [(2118, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(374, 1)], [(64, 1)], [(7, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(4374, 1)], [(49, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(2931, 1)], [(2931, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(720, 1)], [(64, 1)], [(593, 1)], [(593, 1)], [(4165, 1)], [(64, 1)], [(64, 1)], [(950, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(2277, 1)], [(64, 1)], [(64, 1)], [(4425, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(2277, 1)], [(374, 1)], [(64, 1)], [(64, 1)], [(7, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(65, 1)], [(290, 1)], [(374, 1)], [(92, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(3378, 1)], [(64, 1)], [(7, 1)], [(2120, 1)], [(64, 1)], [(720, 1)], [(374, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(4453, 1)], [(64, 1)], [(64, 1)], [(4455, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(374, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(3378, 1)], [(374, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(4425, 1)], [(64, 1)], [(64, 1)], [(720, 1)], [(374, 1)], [(4048, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(4498, 1)], [(64, 1)], [(64, 1)], [(4498, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(1543, 1)], [(4520, 1)], [(64, 1), (177, 1)], [(4498, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(3977, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(7, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(1, 1)], [(64, 1)], [(4455, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(4585, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(7, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(4591, 1)], [(64, 1)], [(64, 1)], [(4592, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(374, 1)], [(64, 1)], [(64, 1)], [(7, 1)], [(64, 1)], [(64, 1)], [(7, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(4688, 1)], [(276, 1)], [(3548, 1)], [(64, 1)], [(4498, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(7, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(1, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(1, 1)], [(64, 1)], [(593, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(593, 1)], [(64, 1)], [(4498, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(290, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(374, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(3427, 1)], [(64, 1)], [(4333, 1)], [(64, 1)], [(3972, 1)], [(64, 1)], [(64, 1)], [(1590, 1)], [(4455, 1)], [(7, 1)], [(64, 1)], [(3470, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(1075, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)], [(64, 1)]]\n"
     ]
    }
   ],
   "source": [
    "# Create Dictionary \n",
    "id2word = corpora.Dictionary(data_lemmatized)  \n",
    "# Create Corpus \n",
    "texts = data_lemmatized  \n",
    "# Term Document Frequency \n",
    "corpus = [id2word.doc2bow(text) for text in texts]  \n",
    "# View \n",
    "print(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[[('telglobalhealth', 1)],\n",
       " [('africa', 1)],\n",
       " [('midst', 1)],\n",
       " [('full', 1)],\n",
       " [('blow', 1)],\n",
       " [('third', 1)],\n",
       " [('wave', 1)],\n",
       " [('coronavirus', 1)],\n",
       " [('head', 1)],\n",
       " [('whoafro', 1)]]"
      ]
     },
     "metadata": {},
     "execution_count": 123
    }
   ],
   "source": [
    "# Readable View\n",
    "[[(id2word[id], freq) for id, freq in cp] for cp in corpus[:10]]"
   ]
  },
  {
   "source": [
    "Building the topic Model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-124-955d1b1fd155>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m lda_model = gensim.models.ldamodel.LdaModel(corpus=corpus,\n\u001b[0m\u001b[0;32m      2\u001b[0m                                            \u001b[0mid2word\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mid2word\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m                                            \u001b[0mnum_topics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m                                            \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m                                            \u001b[0mupdate_every\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Python38\\lib\\site-packages\\gensim\\models\\ldamodel.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, corpus, num_topics, id2word, distributed, chunksize, passes, update_every, alpha, eta, decay, offset, eval_every, iterations, gamma_threshold, minimum_probability, random_state, ns_conf, minimum_phi_value, per_word_topics, callbacks, dtype)\u001b[0m\n\u001b[0;32m    521\u001b[0m             \u001b[0muse_numpy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatcher\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    522\u001b[0m             \u001b[0mstart\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 523\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mchunks_as_numpy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_numpy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    524\u001b[0m             self.add_lifecycle_event(\n\u001b[0;32m    525\u001b[0m                 \u001b[1;34m\"created\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Python38\\lib\\site-packages\\gensim\\models\\ldamodel.py\u001b[0m in \u001b[0;36mupdate\u001b[1;34m(self, corpus, chunksize, decay, offset, passes, update_every, eval_every, iterations, gamma_threshold, chunks_as_numpy)\u001b[0m\n\u001b[0;32m   1006\u001b[0m                         \u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"reached the end of input; now waiting for all remaining jobs to finish\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1007\u001b[0m                         \u001b[0mother\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatcher\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetstate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1008\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdo_mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrho\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpass_\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1009\u001b[0m                     \u001b[1;32mdel\u001b[0m \u001b[0mother\u001b[0m  \u001b[1;31m# frees up memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1010\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Python38\\lib\\site-packages\\gensim\\models\\ldamodel.py\u001b[0m in \u001b[0;36mdo_mstep\u001b[1;34m(self, rho, other, extra_pass)\u001b[0m\n\u001b[0;32m   1056\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1057\u001b[0m         \u001b[0mcurrent_Elogbeta\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_Elogbeta\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1058\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msync_state\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcurrent_Elogbeta\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1059\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1060\u001b[0m         \u001b[1;31m# print out some debug info at the end of each EM iteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Python38\\lib\\site-packages\\gensim\\models\\ldamodel.py\u001b[0m in \u001b[0;36msync_state\u001b[1;34m(self, current_Elogbeta)\u001b[0m\n\u001b[0;32m    621\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcurrent_Elogbeta\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    622\u001b[0m             \u001b[0mcurrent_Elogbeta\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_Elogbeta\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 623\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexpElogbeta\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcurrent_Elogbeta\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    624\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexpElogbeta\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    625\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "lda_model = gensim.models.ldamodel.LdaModel(corpus=corpus,\n",
    "                                           id2word=id2word,\n",
    "                                           num_topics=20, \n",
    "                                           random_state=100,\n",
    "                                           update_every=1,\n",
    "                                           chunksize=100,\n",
    "                                           passes=10,\n",
    "                                           alpha='auto',\n",
    "                                           per_word_topics=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[(0,\n",
      "  '0.088*\"yet\" + 0.081*\"doctor\" + 0.048*\"roger\" + 0.000*\"ce\" + 0.000*\"yard\" + '\n",
      "  '0.000*\"baby\" + 0.000*\"girl\" + 0.000*\"guinea\" + 0.000*\"equatorial\" + '\n",
      "  '0.000*\"chinaeconomy\"'),\n",
      " (1,\n",
      "  '0.642*\"africa\" + 0.091*\"wave\" + 0.071*\"health\" + 0.058*\"good\" + '\n",
      "  '0.000*\"deltavariant\" + 0.000*\"india\" + 0.000*\"israel\" + 0.000*\"uganda\" + '\n",
      "  '0.000*\"dose\" + 0.000*\"expire\"'),\n",
      " (2,\n",
      "  '0.224*\"public\" + 0.051*\"remember\" + 0.007*\"sell\" + 0.000*\"ce\" + '\n",
      "  '0.000*\"baby\" + 0.000*\"girl\" + 0.000*\"guinea\" + 0.000*\"equatorial\" + '\n",
      "  '0.000*\"chinaeconomy\" + 0.000*\"cute\"'),\n",
      " (3,\n",
      "  '0.054*\"policy\" + 0.054*\"amazingly\" + 0.000*\"birth\" + 0.000*\"baby\" + '\n",
      "  '0.000*\"girl\" + 0.000*\"guinea\" + 0.000*\"equatorial\" + 0.000*\"chinaeconomy\" + '\n",
      "  '0.000*\"ce\" + 0.000*\"intense\"'),\n",
      " (4,\n",
      "  '0.253*\"government\" + 0.163*\"head\" + 0.051*\"rise\" + 0.031*\"courageous\" + '\n",
      "  '0.000*\"chinaeconomy\" + 0.000*\"equatorial\" + 0.000*\"guinea\" + 0.000*\"girl\" + '\n",
      "  '0.000*\"unicefafrica\" + 0.000*\"baby\"'),\n",
      " (5,\n",
      "  '0.115*\"pfizer\" + 0.055*\"atlanta\" + 0.048*\"qualified\" + 0.000*\"ce\" + '\n",
      "  '0.000*\"baby\" + 0.000*\"girl\" + 0.000*\"guinea\" + 0.000*\"equatorial\" + '\n",
      "  '0.000*\"chinaeconomy\" + 0.000*\"intense\"'),\n",
      " (6,\n",
      "  '0.228*\"blow\" + 0.043*\"realjoelsmalley\" + 0.026*\"thank\" + '\n",
      "  '0.000*\"unicefafrica\" + 0.000*\"girl\" + 0.000*\"guinea\" + 0.000*\"equatorial\" + '\n",
      "  '0.000*\"chinaeconomy\" + 0.000*\"ce\" + 0.000*\"birth\"'),\n",
      " (7,\n",
      "  '0.817*\"coronavirus\" + 0.051*\"third\" + 0.030*\"expert\" + 0.007*\"easy\" + '\n",
      "  '0.000*\"deltavariant\" + 0.000*\"israel\" + 0.000*\"india\" + 0.000*\"dose\" + '\n",
      "  '0.000*\"expire\" + 0.000*\"liar\"'),\n",
      " (8,\n",
      "  '0.309*\"dr\" + 0.000*\"ce\" + 0.000*\"unicefafrica\" + 0.000*\"baby\" + '\n",
      "  '0.000*\"girl\" + 0.000*\"guinea\" + 0.000*\"equatorial\" + 0.000*\"chinaeconomy\" + '\n",
      "  '0.000*\"cute\" + 0.000*\"birth\"'),\n",
      " (9,\n",
      "  '0.079*\"pleased\" + 0.000*\"ce\" + 0.000*\"unicefafrica\" + 0.000*\"baby\" + '\n",
      "  '0.000*\"girl\" + 0.000*\"guinea\" + 0.000*\"equatorial\" + 0.000*\"chinaeconomy\" + '\n",
      "  '0.000*\"cute\" + 0.000*\"birth\"'),\n",
      " (10,\n",
      "  '0.195*\"go\" + 0.114*\"find\" + 0.000*\"chinaeconomy\" + 0.000*\"birth\" + '\n",
      "  '0.000*\"baby\" + 0.000*\"girl\" + 0.000*\"guinea\" + 0.000*\"equatorial\" + '\n",
      "  '0.000*\"cute\" + 0.000*\"ce\"'),\n",
      " (11,\n",
      "  '0.069*\"speak\" + 0.019*\"warnedcase\" + 0.000*\"yard\" + 0.000*\"girl\" + '\n",
      "  '0.000*\"guinea\" + 0.000*\"equatorial\" + 0.000*\"chinaeconomy\" + 0.000*\"ce\" + '\n",
      "  '0.000*\"birth\" + 0.000*\"intense\"'),\n",
      " (12,\n",
      "  '0.216*\"globalhlthtwit\" + 0.051*\"cdcdirector\" + 0.000*\"ce\" + 0.000*\"intense\" '\n",
      "  '+ 0.000*\"baby\" + 0.000*\"girl\" + 0.000*\"guinea\" + 0.000*\"equatorial\" + '\n",
      "  '0.000*\"chinaeconomy\" + 0.000*\"birth\"'),\n",
      " (13,\n",
      "  '0.233*\"today\" + 0.137*\"know\" + 0.132*\"midst\" + 0.098*\"leader\" + '\n",
      "  '0.039*\"still\" + 0.031*\"medical\" + 0.000*\"deltavariant\" + 0.000*\"india\" + '\n",
      "  '0.000*\"israel\" + 0.000*\"uganda\"'),\n",
      " (14,\n",
      "  '0.992*\"covid\" + 0.000*\"telglobalhealth\" + 0.000*\"israel\" + 0.000*\"dose\" + '\n",
      "  '0.000*\"india\" + 0.000*\"expire\" + 0.000*\"war\" + 0.000*\"crime\" + 0.000*\"load\" '\n",
      "  '+ 0.000*\"try\"'),\n",
      " (15,\n",
      "  '0.858*\"vaccine\" + 0.015*\"whoafro\" + 0.007*\"crazy\" + 0.000*\"deltavariant\" + '\n",
      "  '0.000*\"india\" + 0.000*\"israel\" + 0.000*\"uganda\" + 0.000*\"dose\" + '\n",
      "  '0.000*\"expire\" + 0.000*\"palestinian\"'),\n",
      " (16,\n",
      "  '0.275*\"full\" + 0.165*\"desperate\" + 0.000*\"birth\" + 0.000*\"baby\" + '\n",
      "  '0.000*\"girl\" + 0.000*\"guinea\" + 0.000*\"equatorial\" + 0.000*\"chinaeconomy\" + '\n",
      "  '0.000*\"ce\" + 0.000*\"intense\"'),\n",
      " (17,\n",
      "  '0.200*\"moeti\" + 0.122*\"research\" + 0.000*\"red\" + 0.000*\"ce\" + '\n",
      "  '0.000*\"unicefafrica\" + 0.000*\"girl\" + 0.000*\"guinea\" + 0.000*\"equatorial\" + '\n",
      "  '0.000*\"chinaeconomy\" + 0.000*\"intense\"'),\n",
      " (18,\n",
      "  '0.496*\"amp\" + 0.000*\"birth\" + 0.000*\"yard\" + 0.000*\"girl\" + 0.000*\"guinea\" '\n",
      "  '+ 0.000*\"equatorial\" + 0.000*\"chinaeconomy\" + 0.000*\"ce\" + 0.000*\"intense\" '\n",
      "  '+ 0.000*\"unicefafrica\"'),\n",
      " (19,\n",
      "  '0.067*\"way\" + 0.053*\"hodkinson\" + 0.000*\"ce\" + 0.000*\"unicefafrica\" + '\n",
      "  '0.000*\"baby\" + 0.000*\"girl\" + 0.000*\"guinea\" + 0.000*\"equatorial\" + '\n",
      "  '0.000*\"chinaeconomy\" + 0.000*\"cute\"')]\n",
      "C:\\Python38\\lib\\site-packages\\ipykernel\\ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "# Print the keyword of topics\n",
    "pprint(lda_model.print_topics())\n",
    "doc_lda = lda_model[corpus]"
   ]
  },
  {
   "source": [
    "Evaluating trained topic model using perplexity and cherence score"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Python38\\lib\\site-packages\\ipykernel\\ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n",
      "\n",
      "Perplexity:  -23.871449319949598\n",
      "\n",
      "Coherence Score:  0.7245872265477\n"
     ]
    }
   ],
   "source": [
    "# Compute Perplexity\n",
    "perplexity_score = lda_model.log_perplexity(corpus)\n",
    "print('\\nPerplexity: ', perplexity_score)  \n",
    "# a measure of how good the model is. lower the better.\n",
    "\n",
    "# Compute Coherence Score\n",
    "coherence_model_lda = CoherenceModel(model=lda_model, texts=data_lemmatized, dictionary=id2word, coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence_lda)"
   ]
  },
  {
   "source": [
    "Visualize the topic model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Python38\\lib\\site-packages\\ipykernel\\ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n  and should_run_async(code)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "PreparedData(topic_coordinates=              x         y  topics  cluster       Freq\n",
       "topic                                                \n",
       "14     0.526404 -0.272529       1        1  29.586406\n",
       "15     0.200265  0.147384       2        1  19.204282\n",
       "1      0.170031  0.091339       3        1  11.013467\n",
       "13     0.001997 -0.015487       4        1   7.732088\n",
       "7      0.246144  0.318155       5        1   6.389002\n",
       "4     -0.051346 -0.021307       6        1   3.138708\n",
       "16    -0.061107 -0.021045       7        1   2.963679\n",
       "18    -0.051006 -0.021152       8        1   2.589577\n",
       "6     -0.077565 -0.018943       9        1   2.166022\n",
       "2     -0.078694 -0.018642      10        1   2.002311\n",
       "12    -0.079719 -0.018331      11        1   1.717550\n",
       "5     -0.082902 -0.017234      12        1   1.511703\n",
       "10    -0.076474 -0.019177      13        1   1.449681\n",
       "17    -0.075341 -0.019419      14        1   1.388373\n",
       "8     -0.076349 -0.019170      15        1   1.346757\n",
       "19    -0.087173 -0.014861      16        1   1.333382\n",
       "0     -0.082950 -0.017215      17        1   1.312621\n",
       "11    -0.088212 -0.014016      18        1   1.184181\n",
       "9     -0.088428 -0.013798      19        1   1.026997\n",
       "3     -0.087577 -0.014552      20        1   0.943213, topic_info=           Term         Freq         Total Category  logprob  loglift\n",
       "64        covid  21233.00000  21233.000000  Default  30.0000  30.0000\n",
       "65      vaccine  11910.00000  11910.000000  Default  29.0000  29.0000\n",
       "1        africa   5119.00000   5119.000000  Default  28.0000  28.0000\n",
       "7   coronavirus   3777.00000   3777.000000  Default  27.0000  27.0000\n",
       "29          amp    931.00000    931.000000  Default  26.0000  26.0000\n",
       "..          ...          ...           ...      ...      ...      ...\n",
       "21    desperate      0.12974    357.110805  Topic20  -8.5672  -3.2566\n",
       "23        thank      0.12974     44.800084  Topic20  -8.5672  -1.1808\n",
       "24     research      0.12974    126.396846  Topic20  -8.5672  -2.2180\n",
       "25         note      0.12974      3.870644  Topic20  -8.5672   1.2680\n",
       "26       create      0.12974      3.870673  Topic20  -8.5672   1.2680\n",
       "\n",
       "[1199 rows x 6 columns], token_table=      Topic      Freq             Term\n",
       "term                                  \n",
       "1         3  0.999339           africa\n",
       "68       20  0.909874        amazingly\n",
       "29        8  0.996280              amp\n",
       "59       12  0.943073          atlanta\n",
       "4         9  0.989749             blow\n",
       "56       11  0.947966      cdcdirector\n",
       "7         5  0.998900      coronavirus\n",
       "70        6  0.946639       courageous\n",
       "64        1  0.999802            covid\n",
       "74        2  0.965484            crazy\n",
       "21        7  0.988489        desperate\n",
       "71       17  0.952913           doctor\n",
       "13       15  0.988735               dr\n",
       "61        5  0.887075             easy\n",
       "18        5  0.976792           expert\n",
       "63       13  0.967273             find\n",
       "3         7  0.993825             full\n",
       "12       11  0.987598   globalhlthtwit\n",
       "53       13  0.984405               go\n",
       "15        3  0.991760             good\n",
       "75        6  0.993310       government\n",
       "8         6  0.989734             head\n",
       "17        3  0.993318           health\n",
       "73       16  0.942177        hodkinson\n",
       "20        4  0.994825             know\n",
       "19        4  0.994349           leader\n",
       "42        4  0.980903          medical\n",
       "2         4  0.994652            midst\n",
       "14       14  0.979591            moeti\n",
       "37       12  0.970947           pfizer\n",
       "57       19  0.946222          pleased\n",
       "76       20  0.909846           policy\n",
       "16       10  0.988774           public\n",
       "69       12  0.934972        qualified\n",
       "66        9  0.950889  realjoelsmalley\n",
       "60       10  0.952929         remember\n",
       "24       14  0.973126         research\n",
       "11        6  0.966497             rise\n",
       "72       17  0.921205            roger\n",
       "48       10  0.711458             sell\n",
       "44       18  0.939077            speak\n",
       "51        4  0.986347            still\n",
       "0         1  0.552771  telglobalhealth\n",
       "23        9  0.915177            thank\n",
       "5         5  0.985122            third\n",
       "34        4  0.996979            today\n",
       "65        2  0.999727          vaccine\n",
       "10       18  0.807502       warnedcase\n",
       "6         3  0.995274             wave\n",
       "62       16  0.940440              way\n",
       "9         2  0.982746          whoafro\n",
       "67       17  0.962050              yet, R=30, lambda_step=0.01, plot_opts={'xlab': 'PC1', 'ylab': 'PC2'}, topic_order=[15, 16, 2, 14, 8, 5, 17, 19, 7, 3, 13, 6, 11, 18, 9, 20, 1, 12, 10, 4])"
      ],
      "text/html": "\n<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.3.1/pyLDAvis/js/ldavis.v1.0.0.css\">\n\n\n<div id=\"ldavis_el464026088655212169618053949\"></div>\n<script type=\"text/javascript\">\n\nvar ldavis_el464026088655212169618053949_data = {\"mdsDat\": {\"x\": [0.526403662116261, 0.2002654212745571, 0.17003125375761005, 0.0019970399838841264, 0.24614384813399973, -0.05134569621238815, -0.06110689232934788, -0.05100607001531028, -0.07756468520808868, -0.07869406963113516, -0.07971946218725781, -0.08290210513100883, -0.0764740649462973, -0.07534051324854078, -0.07634854617629545, -0.08717267766326063, -0.082949586891346, -0.08821229517421922, -0.08842792312982643, -0.08757663732198893], \"y\": [-0.2725289570996892, 0.14738422241467575, 0.09133944789420873, -0.015487161826483522, 0.3181545408951886, -0.021306835331640902, -0.021044959858538357, -0.021151872235300278, -0.018943020122453448, -0.018642219929083666, -0.018330557992097624, -0.017233980842431128, -0.019177310405860758, -0.019419497243419476, -0.019170123473696055, -0.014860720047365657, -0.017215044158250564, -0.014015865747382577, -0.013797709859147505, -0.014552375031231213], \"topics\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20], \"cluster\": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], \"Freq\": [29.58640578434587, 19.20428186171412, 11.013467222309544, 7.732087632991432, 6.389001913664097, 3.138708196747085, 2.963679165966127, 2.5895773800663204, 2.166021888358422, 2.002311346917536, 1.7175495629426267, 1.511702796808577, 1.449681339897704, 1.388373423896498, 1.3467565123602994, 1.3333823792146375, 1.3126209991322446, 1.1841807327057263, 1.0269970148492387, 0.943212845111895]}, \"tinfo\": {\"Term\": [\"covid\", \"vaccine\", \"africa\", \"coronavirus\", \"amp\", \"today\", \"full\", \"government\", \"know\", \"midst\", \"wave\", \"blow\", \"leader\", \"dr\", \"head\", \"public\", \"desperate\", \"health\", \"globalhlthtwit\", \"good\", \"go\", \"moeti\", \"third\", \"pfizer\", \"research\", \"still\", \"find\", \"medical\", \"rise\", \"yet\", \"covid\", \"telglobalhealth\", \"israel\", \"dose\", \"india\", \"expire\", \"war\", \"crime\", \"load\", \"try\", \"liar\", \"shawajason\", \"capacity\", \"deltavariant\", \"case\", \"age\", \"limit\", \"min\", \"pin\", \"code\", \"covaxin\", \"people\", \"provide\", \"need\", \"uganda\", \"pmcgvaccine\", \"south\", \"free\", \"palestinian\", \"cuban\", \"vaccine\", \"whoafro\", \"crazy\", \"deltavariant\", \"india\", \"israel\", \"uganda\", \"dose\", \"expire\", \"palestinian\", \"war\", \"crime\", \"load\", \"try\", \"shawajason\", \"liar\", \"cuban\", \"china\", \"astrazeneca\", \"capacity\", \"bihar\", \"case\", \"age\", \"min\", \"limit\", \"pin\", \"code\", \"tanzania\", \"covaxin\", \"provide\", \"africa\", \"wave\", \"health\", \"good\", \"deltavariant\", \"uganda\", \"israel\", \"india\", \"palestinian\", \"cuban\", \"expire\", \"dose\", \"war\", \"crime\", \"load\", \"shawajason\", \"liar\", \"try\", \"china\", \"astrazeneca\", \"bihar\", \"capacity\", \"age\", \"tanzania\", \"case\", \"min\", \"limit\", \"pin\", \"code\", \"vaccinequity\", \"people\", \"covaxin\", \"today\", \"know\", \"midst\", \"leader\", \"still\", \"medical\", \"nhsrdforum\", \"amazing\", \"campaign\", \"peterhotez\", \"brain\", \"aid\", \"agent\", \"notice\", \"victim\", \"stroke\", \"pass\", \"pathetically\", \"disrespectful\", \"mere\", \"hund\", \"falcicchio\", \"join\", \"training\", \"dc\", \"corpsthey\", \"door\", \"attend\", \"vaxhunterscan\", \"mb\", \"la\", \"individual\", \"jab\", \"guy\", \"straight\", \"instead\", \"junk\", \"attention\", \"drive\", \"rgrosjean\", \"excited\", \"race\", \"roadamerica\", \"weekend\", \"gogiveone\", \"true\", \"production\", \"sivathambisetty\", \"page\", \"ad\", \"prion\", \"title\", \"modern\", \"tmv\", \"tighten\", \"stat\", \"medium\", \"bihar\", \"migo\", \"chuckschumer\", \"ctru\", \"dumaguete\", \"tanzania\", \"southkorea\", \"exercise\", \"sleevesupplacer\", \"fauciemail\", \"poorercountrie\", \"expertskisuno\", \"uninterrupted\", \"eritrea\", \"tigray\", \"nstnation\", \"zimbabwe\", \"vandalurzoo\", \"cornwall\", \"ethiopia\", \"blantyre\", \"joebiden\", \"ccpchina\", \"singaporemoh\", \"covax\", \"cabalworld\", \"vaccineequity\", \"chumakov\", \"tripswaiver\", \"actor\", \"covidvaccine\", \"askcuexpert\", \"iso\", \"unsc\", \"sarscov\", \"palestine\", \"china\", \"astrazeneca\", \"getvaccinate\", \"palestinian\", \"taiwan\", \"yuoksambath\", \"uganda\", \"cuban\", \"deltavariant\", \"vaccinequity\", \"sinovac\", \"ernreconnet\", \"goc\", \"risk\", \"india\", \"israel\", \"war\", \"crime\", \"try\", \"load\", \"shawajason\", \"liar\", \"expire\", \"dose\", \"capacity\", \"case\", \"age\", \"min\", \"limit\", \"pin\", \"coronavirus\", \"third\", \"expert\", \"easy\", \"nhsrdforum\", \"amazing\", \"campaign\", \"peterhotez\", \"brain\", \"aid\", \"agent\", \"notice\", \"victim\", \"stroke\", \"pass\", \"pathetically\", \"disrespectful\", \"mere\", \"hund\", \"falcicchio\", \"join\", \"training\", \"dc\", \"corpsthey\", \"door\", \"attend\", \"vaxhunterscan\", \"mb\", \"winnipeg\", \"scurfield\", \"mugkip\", \"shib\", \"mrk\", \"pollachi\", \"stephencurry\", \"tedro\", \"mom\", \"bease\", \"beansprout\", \"dammit\", \"protective\", \"brazilian\", \"actual\", \"diddr\", \"nothingisunreal\", \"lucienmusique\", \"jm\", \"heretorebuild\", \"ab\", \"abila\", \"confirm\", \"trtworld\", \"arrive\", \"careful\", \"fix\", \"protein\", \"bastard\", \"ryan\", \"petestone\", \"boblefridge\", \"twist\", \"deendayal\", \"memorial\", \"hospit\", \"ramchanderrao\", \"jammu\", \"gujjar\", \"bakarwal\", \"bjp\", \"bmcc\", \"pvtvaccine\", \"aged\", \"conduct\", \"piece\", \"presentation\", \"informative\", \"extreme\", \"wake\", \"bjgmc\", \"staff\", \"shoot\", \"technology\", \"woman\", \"reach\", \"remote\", \"leave\", \"digital\", \"vibe\", \"shawajason\", \"liar\", \"try\", \"load\", \"war\", \"crime\", \"expire\", \"provide\", \"pin\", \"code\", \"capacity\", \"min\", \"limit\", \"case\", \"people\", \"south\", \"age\", \"free\", \"designer\", \"zweli\", \"givenkazeni\", \"firework\", \"graphic\", \"new\", \"pmcgvaccine\", \"base\", \"dose\", \"israel\", \"covaxin\", \"india\", \"need\", \"uganda\", \"deltavariant\", \"cuban\", \"palestinian\", \"china\", \"government\", \"head\", \"rise\", \"courageous\", \"nhsrdforum\", \"amazing\", \"campaign\", \"peterhotez\", \"brain\", \"aid\", \"agent\", \"notice\", \"victim\", \"stroke\", \"pass\", \"pathetically\", \"disrespectful\", \"mere\", \"hund\", \"falcicchio\", \"join\", \"training\", \"dc\", \"corpsthey\", \"door\", \"attend\", \"vaxhunterscan\", \"mb\", \"winnipeg\", \"scurfield\", \"telglobalhealth\", \"africa\", \"midst\", \"full\", \"blow\", \"third\", \"wave\", \"coronavirus\", \"whoafro\", \"warnedcase\", \"globalhlthtwit\", \"dr\", \"moeti\", \"good\", \"public\", \"health\", \"expert\", \"leader\", \"know\", \"desperate\", \"thank\", \"research\", \"note\", \"create\", \"full\", \"desperate\", \"nhsrdforum\", \"amazing\", \"campaign\", \"peterhotez\", \"brain\", \"aid\", \"agent\", \"notice\", \"victim\", \"stroke\", \"pass\", \"pathetically\", \"disrespectful\", \"mere\", \"hund\", \"falcicchio\", \"join\", \"training\", \"dc\", \"corpsthey\", \"door\", \"attend\", \"vaxhunterscan\", \"mb\", \"winnipeg\", \"scurfield\", \"pharmacy\", \"blvd\", \"telglobalhealth\", \"africa\", \"midst\", \"blow\", \"third\", \"wave\", \"coronavirus\", \"head\", \"whoafro\", \"warnedcase\", \"rise\", \"globalhlthtwit\", \"dr\", \"moeti\", \"good\", \"public\", \"health\", \"expert\", \"leader\", \"know\", \"thank\", \"research\", \"note\", \"create\", \"amp\", \"amp\", \"nhsrdforum\", \"amazing\", \"campaign\", \"peterhotez\", \"brain\", \"aid\", \"agent\", \"notice\", \"victim\", \"stroke\", \"pass\", \"pathetically\", \"disrespectful\", \"mere\", \"hund\", \"falcicchio\", \"join\", \"training\", \"dc\", \"corpsthey\", \"door\", \"attend\", \"vaxhunterscan\", \"mb\", \"winnipeg\", \"scurfield\", \"pharmacy\", \"blvd\", \"gebauerken\", \"telglobalhealth\", \"africa\", \"midst\", \"full\", \"blow\", \"third\", \"wave\", \"coronavirus\", \"head\", \"whoafro\", \"warnedcase\", \"rise\", \"globalhlthtwit\", \"dr\", \"moeti\", \"good\", \"public\", \"health\", \"expert\", \"leader\", \"know\", \"desperate\", \"thank\", \"research\", \"note\", \"create\", \"blow\", \"realjoelsmalley\", \"thank\", \"nhsrdforum\", \"amazing\", \"campaign\", \"peterhotez\", \"brain\", \"aid\", \"agent\", \"notice\", \"victim\", \"stroke\", \"pass\", \"pathetically\", \"disrespectful\", \"mere\", \"hund\", \"falcicchio\", \"join\", \"training\", \"dc\", \"corpsthey\", \"door\", \"attend\", \"vaxhunterscan\", \"mb\", \"winnipeg\", \"scurfield\", \"pharmacy\", \"telglobalhealth\", \"africa\", \"midst\", \"full\", \"third\", \"wave\", \"coronavirus\", \"head\", \"whoafro\", \"warnedcase\", \"rise\", \"globalhlthtwit\", \"dr\", \"moeti\", \"good\", \"public\", \"health\", \"expert\", \"leader\", \"know\", \"desperate\", \"research\", \"note\", \"create\", \"public\", \"remember\", \"sell\", \"nhsrdforum\", \"amazing\", \"campaign\", \"peterhotez\", \"brain\", \"aid\", \"agent\", \"notice\", \"victim\", \"stroke\", \"pass\", \"pathetically\", \"disrespectful\", \"mere\", \"hund\", \"falcicchio\", \"join\", \"training\", \"dc\", \"corpsthey\", \"door\", \"attend\", \"vaxhunterscan\", \"mb\", \"winnipeg\", \"scurfield\", \"pharmacy\", \"telglobalhealth\", \"africa\", \"midst\", \"full\", \"blow\", \"third\", \"wave\", \"coronavirus\", \"head\", \"whoafro\", \"warnedcase\", \"rise\", \"globalhlthtwit\", \"dr\", \"moeti\", \"good\", \"health\", \"expert\", \"leader\", \"know\", \"desperate\", \"thank\", \"research\", \"note\", \"create\", \"globalhlthtwit\", \"cdcdirector\", \"nhsrdforum\", \"amazing\", \"campaign\", \"peterhotez\", \"brain\", \"aid\", \"agent\", \"notice\", \"victim\", \"stroke\", \"pass\", \"pathetically\", \"disrespectful\", \"mere\", \"hund\", \"falcicchio\", \"join\", \"training\", \"dc\", \"corpsthey\", \"door\", \"attend\", \"vaxhunterscan\", \"mb\", \"winnipeg\", \"scurfield\", \"pharmacy\", \"blvd\", \"telglobalhealth\", \"africa\", \"midst\", \"full\", \"blow\", \"third\", \"wave\", \"coronavirus\", \"head\", \"whoafro\", \"warnedcase\", \"rise\", \"dr\", \"moeti\", \"good\", \"public\", \"health\", \"expert\", \"leader\", \"know\", \"desperate\", \"thank\", \"research\", \"note\", \"create\", \"pfizer\", \"atlanta\", \"qualified\", \"nhsrdforum\", \"amazing\", \"campaign\", \"peterhotez\", \"brain\", \"aid\", \"agent\", \"notice\", \"victim\", \"stroke\", \"pass\", \"pathetically\", \"disrespectful\", \"mere\", \"hund\", \"falcicchio\", \"join\", \"training\", \"dc\", \"corpsthey\", \"door\", \"attend\", \"vaxhunterscan\", \"mb\", \"winnipeg\", \"scurfield\", \"pharmacy\", \"telglobalhealth\", \"africa\", \"midst\", \"full\", \"blow\", \"third\", \"wave\", \"coronavirus\", \"head\", \"whoafro\", \"warnedcase\", \"rise\", \"globalhlthtwit\", \"dr\", \"moeti\", \"good\", \"public\", \"health\", \"expert\", \"leader\", \"know\", \"desperate\", \"thank\", \"research\", \"note\", \"create\", \"go\", \"find\", \"nhsrdforum\", \"amazing\", \"campaign\", \"peterhotez\", \"brain\", \"aid\", \"agent\", \"notice\", \"victim\", \"stroke\", \"pass\", \"pathetically\", \"disrespectful\", \"mere\", \"hund\", \"falcicchio\", \"join\", \"training\", \"dc\", \"corpsthey\", \"door\", \"attend\", \"vaxhunterscan\", \"mb\", \"winnipeg\", \"scurfield\", \"pharmacy\", \"blvd\", \"telglobalhealth\", \"africa\", \"midst\", \"full\", \"blow\", \"third\", \"wave\", \"coronavirus\", \"head\", \"whoafro\", \"warnedcase\", \"rise\", \"globalhlthtwit\", \"dr\", \"moeti\", \"good\", \"public\", \"health\", \"expert\", \"leader\", \"know\", \"desperate\", \"thank\", \"research\", \"note\", \"create\", \"moeti\", \"research\", \"red\", \"nhsrdforum\", \"amazing\", \"campaign\", \"peterhotez\", \"brain\", \"aid\", \"agent\", \"notice\", \"victim\", \"stroke\", \"pass\", \"pathetically\", \"disrespectful\", \"mere\", \"hund\", \"falcicchio\", \"join\", \"training\", \"dc\", \"corpsthey\", \"door\", \"attend\", \"vaxhunterscan\", \"mb\", \"winnipeg\", \"scurfield\", \"pharmacy\", \"telglobalhealth\", \"africa\", \"midst\", \"full\", \"blow\", \"third\", \"wave\", \"coronavirus\", \"head\", \"whoafro\", \"warnedcase\", \"rise\", \"globalhlthtwit\", \"dr\", \"good\", \"public\", \"health\", \"expert\", \"leader\", \"know\", \"desperate\", \"thank\", \"note\", \"create\", \"dr\", \"nhsrdforum\", \"amazing\", \"campaign\", \"peterhotez\", \"brain\", \"aid\", \"agent\", \"notice\", \"victim\", \"stroke\", \"pass\", \"pathetically\", \"disrespectful\", \"mere\", \"hund\", \"falcicchio\", \"join\", \"training\", \"dc\", \"corpsthey\", \"door\", \"attend\", \"vaxhunterscan\", \"mb\", \"winnipeg\", \"scurfield\", \"pharmacy\", \"blvd\", \"gebauerken\", \"telglobalhealth\", \"africa\", \"midst\", \"full\", \"blow\", \"third\", \"wave\", \"coronavirus\", \"head\", \"whoafro\", \"warnedcase\", \"rise\", \"globalhlthtwit\", \"moeti\", \"good\", \"public\", \"health\", \"expert\", \"leader\", \"know\", \"desperate\", \"thank\", \"research\", \"note\", \"create\", \"amp\", \"way\", \"hodkinson\", \"nhsrdforum\", \"amazing\", \"campaign\", \"peterhotez\", \"brain\", \"aid\", \"agent\", \"notice\", \"victim\", \"stroke\", \"pass\", \"pathetically\", \"disrespectful\", \"mere\", \"hund\", \"falcicchio\", \"join\", \"training\", \"dc\", \"corpsthey\", \"door\", \"attend\", \"vaxhunterscan\", \"mb\", \"winnipeg\", \"scurfield\", \"pharmacy\", \"blvd\", \"telglobalhealth\", \"africa\", \"midst\", \"full\", \"blow\", \"third\", \"wave\", \"coronavirus\", \"head\", \"whoafro\", \"warnedcase\", \"rise\", \"globalhlthtwit\", \"dr\", \"moeti\", \"good\", \"public\", \"health\", \"expert\", \"leader\", \"know\", \"desperate\", \"thank\", \"research\", \"note\", \"create\", \"yet\", \"doctor\", \"roger\", \"nhsrdforum\", \"amazing\", \"campaign\", \"peterhotez\", \"brain\", \"aid\", \"agent\", \"notice\", \"victim\", \"stroke\", \"pass\", \"pathetically\", \"disrespectful\", \"mere\", \"hund\", \"falcicchio\", \"join\", \"training\", \"dc\", \"corpsthey\", \"door\", \"attend\", \"vaxhunterscan\", \"mb\", \"winnipeg\", \"scurfield\", \"pharmacy\", \"telglobalhealth\", \"africa\", \"midst\", \"full\", \"blow\", \"third\", \"wave\", \"coronavirus\", \"head\", \"whoafro\", \"warnedcase\", \"rise\", \"globalhlthtwit\", \"dr\", \"moeti\", \"good\", \"public\", \"health\", \"expert\", \"leader\", \"know\", \"desperate\", \"thank\", \"research\", \"note\", \"create\", \"speak\", \"warnedcase\", \"nhsrdforum\", \"amazing\", \"campaign\", \"peterhotez\", \"brain\", \"aid\", \"agent\", \"notice\", \"victim\", \"stroke\", \"pass\", \"pathetically\", \"disrespectful\", \"mere\", \"hund\", \"falcicchio\", \"join\", \"training\", \"dc\", \"corpsthey\", \"door\", \"attend\", \"vaxhunterscan\", \"mb\", \"winnipeg\", \"scurfield\", \"pharmacy\", \"blvd\", \"telglobalhealth\", \"africa\", \"midst\", \"full\", \"blow\", \"third\", \"wave\", \"coronavirus\", \"head\", \"whoafro\", \"rise\", \"globalhlthtwit\", \"dr\", \"moeti\", \"good\", \"public\", \"health\", \"expert\", \"leader\", \"know\", \"desperate\", \"thank\", \"research\", \"note\", \"create\", \"pleased\", \"nhsrdforum\", \"amazing\", \"campaign\", \"peterhotez\", \"brain\", \"aid\", \"agent\", \"notice\", \"victim\", \"stroke\", \"pass\", \"pathetically\", \"disrespectful\", \"mere\", \"hund\", \"falcicchio\", \"join\", \"training\", \"dc\", \"corpsthey\", \"door\", \"attend\", \"vaxhunterscan\", \"mb\", \"winnipeg\", \"scurfield\", \"pharmacy\", \"blvd\", \"gebauerken\", \"telglobalhealth\", \"africa\", \"midst\", \"full\", \"blow\", \"third\", \"wave\", \"coronavirus\", \"head\", \"whoafro\", \"warnedcase\", \"rise\", \"globalhlthtwit\", \"dr\", \"moeti\", \"good\", \"public\", \"health\", \"expert\", \"leader\", \"know\", \"desperate\", \"thank\", \"research\", \"note\", \"create\", \"policy\", \"amazingly\", \"nhsrdforum\", \"amazing\", \"campaign\", \"peterhotez\", \"brain\", \"aid\", \"agent\", \"notice\", \"victim\", \"stroke\", \"pass\", \"pathetically\", \"disrespectful\", \"mere\", \"hund\", \"falcicchio\", \"join\", \"training\", \"dc\", \"corpsthey\", \"door\", \"attend\", \"vaxhunterscan\", \"mb\", \"winnipeg\", \"scurfield\", \"pharmacy\", \"blvd\", \"telglobalhealth\", \"africa\", \"midst\", \"full\", \"blow\", \"third\", \"wave\", \"coronavirus\", \"head\", \"whoafro\", \"warnedcase\", \"rise\", \"globalhlthtwit\", \"dr\", \"moeti\", \"good\", \"public\", \"health\", \"expert\", \"leader\", \"know\", \"desperate\", \"thank\", \"research\", \"note\", \"create\"], \"Freq\": [21233.0, 11910.0, 5119.0, 3777.0, 931.0, 1304.0, 593.0, 576.0, 766.0, 741.0, 724.0, 360.0, 549.0, 304.0, 373.0, 327.0, 357.0, 570.0, 271.0, 464.0, 208.0, 204.0, 239.0, 129.0, 126.0, 224.0, 123.0, 174.0, 120.0, 87.0, 21229.368568561073, 5.20806192464203, 0.0334420586264774, 0.03343993803421036, 0.03343788310248369, 0.03343306070057366, 0.03342213186840842, 0.03342213186840842, 0.03342206377599618, 0.033422022434174456, 0.03342200054732766, 0.0334219981154558, 0.03340584075877893, 0.033421042389812514, 0.03339993617388858, 0.03339827034166046, 0.03339801985885828, 0.03339801742698641, 0.03339786178718699, 0.03339786178718699, 0.03339357196521559, 0.03339338957482565, 0.03339330202743848, 0.03339091149739432, 0.033392903200452476, 0.03338697429684347, 0.033386042889918845, 0.03338525009969057, 0.03338903409231387, 0.0333875141723977, 11906.73253684275, 212.2066789299975, 101.09534538769866, 0.35725889902250624, 0.3562371376651125, 0.3561089123731536, 0.35597886864097, 0.35597699968851676, 0.3559180014056694, 0.35590759588660564, 0.35580184853631375, 0.35580184853631375, 0.3558012929018006, 0.35580083829174447, 0.35580066149894485, 0.35580066149894485, 0.35577222311431894, 0.3557022384217804, 0.3556437957734462, 0.35562823800707893, 0.3556230605036612, 0.35557403838593576, 0.35555062596804216, 0.35554827714941856, 0.35554827714941856, 0.35554741844153465, 0.35554741844153465, 0.3555235514135848, 0.3555195104353076, 0.355505872133622, 5115.745434783946, 720.7871803017889, 567.1776816842538, 461.1940392350141, 0.23450210787972023, 0.2343968371959258, 0.23440613600976676, 0.23441433402944584, 0.234388277072904, 0.23437752984569218, 0.2343896530656063, 0.23439385346438182, 0.2343802383786957, 0.2343802383786957, 0.23438018044216086, 0.234380122505626, 0.234380122505626, 0.23438013698975974, 0.23436963599282096, 0.2343650010700342, 0.23436269809277452, 0.23436446515708698, 0.23435754174117424, 0.23435425384282238, 0.2343591349958822, 0.2343572955109012, 0.2343572955109012, 0.2343571651536978, 0.2343571651536978, 0.23435018380125025, 0.23435348618373583, 0.23435445662069432, 1301.4666980333102, 763.4930356903853, 738.4924541674832, 545.6272789934686, 220.58350367255997, 170.85359260457776, 0.39499901904126955, 0.39499901904126955, 0.39499901904126955, 0.39499901904126955, 0.39499901904126955, 0.39499901904126955, 0.39499901904126955, 0.39499901904126955, 0.39499901904126955, 0.39499901904126955, 0.39499901904126955, 0.39499901904126955, 0.39499901904126955, 0.39499901904126955, 0.39499901904126955, 0.39499901904126955, 0.39499901904126955, 0.39499901904126955, 0.39499901904126955, 0.39499901904126955, 0.39499901904126955, 0.39499901904126955, 0.39499901904126955, 0.39499901904126955, 0.39499905971605026, 0.39499905971605026, 0.39499905971605026, 0.39499905971605026, 0.39499905971605026, 0.39499905971605026, 0.39499905971605026, 0.39499905971605026, 0.39499905971605026, 0.39499905971605026, 0.39499905971605026, 0.39499905971605026, 0.39499905971605026, 0.39499905971605026, 0.39499905971605026, 0.39499905971605026, 0.39499905971605026, 0.39499905971605026, 0.39499905971605026, 0.39499905971605026, 0.39499905971605026, 0.39499905971605026, 0.39499905971605026, 0.39499905971605026, 0.394999100390831, 0.394999100390831, 0.394999100390831, 0.39501569570137435, 0.39500154087767564, 0.39500023928469186, 0.39500023928469186, 0.39500023928469186, 0.39501146552417704, 0.3950003613090341, 0.3950003613090341, 0.3950003613090341, 0.3950017849263601, 0.3950004833333763, 0.3950004833333763, 0.3950004833333763, 0.3950004833333763, 0.3950006460324993, 0.39500174425157936, 0.39500027995947257, 0.39500027995947257, 0.39500027995947257, 0.39500027995947257, 0.39500027995947257, 0.3950004833333763, 0.3950005646829378, 0.395008618289525, 0.395007357371322, 0.39500568970531147, 0.3950034525923706, 0.3950060964531189, 0.39500869963908647, 0.3950049575592581, 0.39500377799061653, 0.3950026390967557, 0.395002110324606, 0.39500304584456314, 0.3950083335660598, 0.3950018662759216, 0.39501842091168415, 0.3950160210996203, 0.39500605577833814, 0.39502651519305215, 0.39500398136452025, 0.3950028424706594, 0.39502928107814267, 0.39502086139852877, 0.39507817216459634, 0.39500869963908647, 0.3950058524044344, 0.39500524228272327, 0.395003859340178, 0.3950078047939101, 0.3950344467752971, 0.3950304199720035, 0.39501964115510646, 0.39501964115510646, 0.39501960048032575, 0.39501960048032575, 0.395019559805545, 0.395019559805545, 0.3950233018853734, 0.395024481454015, 0.39501325521452973, 0.39501118080071185, 0.39501053000421993, 0.39501044865465845, 0.39501044865465845, 0.395010367305097, 3773.379506487213, 235.78703857426396, 138.52548722871467, 33.423801831796766, 0.09351793906769404, 0.09351793906769404, 0.09351793906769404, 0.09351793906769404, 0.09351793906769404, 0.09351793906769404, 0.09351793906769404, 0.09351793906769404, 0.09351793906769404, 0.09351793906769404, 0.09351793906769404, 0.09351793906769404, 0.09351793906769404, 0.09351793906769404, 0.09351793906769404, 0.09351793906769404, 0.09351793906769404, 0.09351793906769404, 0.09351793906769404, 0.09351793906769404, 0.09351793906769404, 0.09351793906769404, 0.09351793906769404, 0.09351793906769404, 0.09351793906769404, 0.09351793906769404, 0.0935179474700578, 0.0935179474700578, 0.0935179474700578, 0.0935179474700578, 0.0935179474700578, 0.0935179474700578, 0.0935179474700578, 0.0935179474700578, 0.0935179474700578, 0.0935179474700578, 0.0935179474700578, 0.0935179474700578, 0.0935179474700578, 0.0935179474700578, 0.0935179474700578, 0.0935179474700578, 0.0935179474700578, 0.0935179474700578, 0.0935179474700578, 0.0935179474700578, 0.0935179474700578, 0.0935179474700578, 0.0935179474700578, 0.0935179474700578, 0.0935179474700578, 0.0935179474700578, 0.09351795587242158, 0.09351795587242158, 0.09351795587242158, 0.09351795587242158, 0.09351795587242158, 0.09351797267714912, 0.09351797267714912, 0.09351797267714912, 0.09351797267714912, 0.09351797267714912, 0.09351797267714912, 0.09351797267714912, 0.09351797267714912, 0.09351797267714912, 0.09351797267714912, 0.09351797267714912, 0.09351797267714912, 0.09351797267714912, 0.09351797267714912, 0.09351797267714912, 0.09351797267714912, 0.09351797267714912, 0.09351797267714912, 0.09351797267714912, 0.09351797267714912, 0.09351795587242158, 0.0935180062866042, 0.09351797267714912, 0.09351797267714912, 0.09351799788424044, 0.09351799788424044, 0.09351799788424044, 0.0935190229726205, 0.0935190229726205, 0.0935190229726205, 0.0935190229726205, 0.0935190229726205, 0.0935190229726205, 0.09351920782462346, 0.09351847681897538, 0.09351854403788555, 0.09351854403788555, 0.09351868687806966, 0.09351854403788555, 0.09351854403788555, 0.09351858604970441, 0.09351846001424784, 0.09351833397879128, 0.09351854403788555, 0.09351830877169996, 0.09351825835751734, 0.09351825835751734, 0.09351825835751734, 0.09351825835751734, 0.0935182667598811, 0.09351825835751734, 0.09351833397879128, 0.09351814072442455, 0.0935192834458974, 0.09351945989553659, 0.09351846001424784, 0.09351935066480757, 0.0935183843929739, 0.09351891374189147, 0.09352014048700205, 0.09351865326861457, 0.09351869528043343, 0.09351846001424784, 573.2320236546801, 370.2106395440326, 116.39377100487076, 69.26215412837334, 0.24336974954116333, 0.24336974954116333, 0.24336974954116333, 0.24336974954116333, 0.24336974954116333, 0.24336974954116333, 0.24336974954116333, 0.24336974954116333, 0.24336974954116333, 0.24336974954116333, 0.24336974954116333, 0.24336974954116333, 0.24336974954116333, 0.24336974954116333, 0.24336974954116333, 0.24336974954116333, 0.24336974954116333, 0.24336974954116333, 0.24336974954116333, 0.24336974954116333, 0.24336974954116333, 0.24336974954116333, 0.24336974954116333, 0.24336974954116333, 0.24336974954116333, 0.24336974954116333, 0.24336974954116333, 0.24336974954116333, 0.24336974954116333, 0.24336974954116333, 0.24336974954116333, 0.24336974954116333, 0.24336974954116333, 0.24336974954116333, 0.24336974954116333, 0.24336974954116333, 0.24336974954116333, 0.24336974954116333, 0.24336974954116333, 0.24336974954116333, 0.24336974954116333, 0.24336974954116333, 0.24336974954116333, 0.24336974954116333, 0.24336974954116333, 0.24336974954116333, 0.24336974954116333, 0.24336974954116333, 0.24336974954116333, 0.24336974954116333, 590.0509831157347, 353.49601651700436, 0.2558550836718777, 0.2558550836718777, 0.2558550836718777, 0.2558550836718777, 0.2558550836718777, 0.2558550836718777, 0.2558550836718777, 0.2558550836718777, 0.2558550836718777, 0.2558550836718777, 0.2558550836718777, 0.2558550836718777, 0.2558550836718777, 0.2558550836718777, 0.2558550836718777, 0.2558550836718777, 0.2558550836718777, 0.2558550836718777, 0.2558550836718777, 0.2558550836718777, 0.2558550836718777, 0.2558550836718777, 0.2558550836718777, 0.2558550836718777, 0.2558550836718777, 0.2558550836718777, 0.2558550836718777, 0.2558550836718777, 0.2558550836718777, 0.2558550836718777, 0.2558550836718777, 0.2558550836718777, 0.2558550836718777, 0.2558550836718777, 0.2558550836718777, 0.2558550836718777, 0.2558550836718777, 0.2558550836718777, 0.2558550836718777, 0.2558550836718777, 0.2558550836718777, 0.2558550836718777, 0.2558550836718777, 0.2558550836718777, 0.2558550836718777, 0.2558550836718777, 0.2558550836718777, 0.2558550836718777, 0.2558550836718777, 0.2558550836718777, 0.2558550836718777, 0.2558550836718777, 0.2558550836718777, 927.7956824608009, 0.20146518258410606, 0.20146518258410606, 0.20146518258410606, 0.20146518258410606, 0.20146518258410606, 0.20146518258410606, 0.20146518258410606, 0.20146518258410606, 0.20146518258410606, 0.20146518258410606, 0.20146518258410606, 0.20146518258410606, 0.20146518258410606, 0.20146518258410606, 0.20146518258410606, 0.20146518258410606, 0.20146518258410606, 0.20146518258410606, 0.20146518258410606, 0.20146518258410606, 0.20146518258410606, 0.20146518258410606, 0.20146518258410606, 0.20146518258410606, 0.20146518258410606, 0.20146518258410606, 0.20146518258410606, 0.20146518258410606, 0.20146518258410606, 0.20146518258410606, 0.20146518258410606, 0.20146518258410606, 0.20146518258410606, 0.20146518258410606, 0.20146518258410606, 0.20146518258410606, 0.20146518258410606, 0.20146518258410606, 0.20146518258410606, 0.20146518258410606, 0.20146518258410606, 0.20146518258410606, 0.20146518258410606, 0.20146518258410606, 0.20146518258410606, 0.20146518258410606, 0.20146518258410606, 0.20146518258410606, 0.20146518258410606, 0.20146518258410606, 0.20146518258410606, 0.20146518258410606, 0.20146518258410606, 0.20146518258410606, 0.20146518258410606, 357.0617290990884, 66.82468168034146, 41.16439191814357, 0.23495152596132104, 0.23495152596132104, 0.23495152596132104, 0.23495152596132104, 0.23495152596132104, 0.23495152596132104, 0.23495152596132104, 0.23495152596132104, 0.23495152596132104, 0.23495152596132104, 0.23495152596132104, 0.23495152596132104, 0.23495152596132104, 0.23495152596132104, 0.23495152596132104, 0.23495152596132104, 0.23495152596132104, 0.23495152596132104, 0.23495152596132104, 0.23495152596132104, 0.23495152596132104, 0.23495152596132104, 0.23495152596132104, 0.23495152596132104, 0.23495152596132104, 0.23495152596132104, 0.23495152596132104, 0.23495152596132104, 0.23495152596132104, 0.23495152596132104, 0.23495152596132104, 0.23495152596132104, 0.23495152596132104, 0.23495152596132104, 0.23495152596132104, 0.23495152596132104, 0.23495152596132104, 0.23495152596132104, 0.23495152596132104, 0.23495152596132104, 0.23495152596132104, 0.23495152596132104, 0.23495152596132104, 0.23495152596132104, 0.23495152596132104, 0.23495152596132104, 0.23495152596132104, 0.23495152596132104, 0.23495152596132104, 0.23495152596132104, 0.23495152596132104, 324.0295656758993, 74.00647488183637, 10.406780998230893, 0.22177297589431944, 0.22177297589431944, 0.22177297589431944, 0.22177297589431944, 0.22177297589431944, 0.22177297589431944, 0.22177297589431944, 0.22177297589431944, 0.22177297589431944, 0.22177297589431944, 0.22177297589431944, 0.22177297589431944, 0.22177297589431944, 0.22177297589431944, 0.22177297589431944, 0.22177297589431944, 0.22177297589431944, 0.22177297589431944, 0.22177297589431944, 0.22177297589431944, 0.22177297589431944, 0.22177297589431944, 0.22177297589431944, 0.22177297589431944, 0.22177297589431944, 0.22177297589431944, 0.22177297589431944, 0.22177297589431944, 0.22177297589431944, 0.22177297589431944, 0.22177297589431944, 0.22177297589431944, 0.22177297589431944, 0.22177297589431944, 0.22177297589431944, 0.22177297589431944, 0.22177297589431944, 0.22177297589431944, 0.22177297589431944, 0.22177297589431944, 0.22177297589431944, 0.22177297589431944, 0.22177297589431944, 0.22177297589431944, 0.22177297589431944, 0.22177297589431944, 0.22177297589431944, 0.22177297589431944, 0.22177297589431944, 0.22177297589431944, 0.22177297589431944, 0.22177297589431944, 267.68916603665355, 63.83652667531222, 0.19421005245171627, 0.19421005245171627, 0.19421005245171627, 0.19421005245171627, 0.19421005245171627, 0.19421005245171627, 0.19421005245171627, 0.19421005245171627, 0.19421005245171627, 0.19421005245171627, 0.19421005245171627, 0.19421005245171627, 0.19421005245171627, 0.19421005245171627, 0.19421005245171627, 0.19421005245171627, 0.19421005245171627, 0.19421005245171627, 0.19421005245171627, 0.19421005245171627, 0.19421005245171627, 0.19421005245171627, 0.19421005245171627, 0.19421005245171627, 0.19421005245171627, 0.19421005245171627, 0.19421005245171627, 0.19421005245171627, 0.19421005245171627, 0.19421005245171627, 0.19421005245171627, 0.19421005245171627, 0.19421005245171627, 0.19421005245171627, 0.19421005245171627, 0.19421005245171627, 0.19421005245171627, 0.19421005245171627, 0.19421005245171627, 0.19421005245171627, 0.19421005245171627, 0.19421005245171627, 0.19421005245171627, 0.19421005245171627, 0.19421005245171627, 0.19421005245171627, 0.19421005245171627, 0.19421005245171627, 0.19421005245171627, 0.19421005245171627, 0.19421005245171627, 0.19421005245171627, 0.19421005245171627, 126.08202219414926, 59.93359237524632, 51.92845318775848, 0.1824620220590215, 0.1824620220590215, 0.1824620220590215, 0.1824620220590215, 0.1824620220590215, 0.1824620220590215, 0.1824620220590215, 0.1824620220590215, 0.1824620220590215, 0.1824620220590215, 0.1824620220590215, 0.1824620220590215, 0.1824620220590215, 0.1824620220590215, 0.1824620220590215, 0.1824620220590215, 0.1824620220590215, 0.1824620220590215, 0.1824620220590215, 0.1824620220590215, 0.1824620220590215, 0.1824620220590215, 0.1824620220590215, 0.1824620220590215, 0.1824620220590215, 0.1824620220590215, 0.1824620220590215, 0.1824620220590215, 0.1824620220590215, 0.1824620220590215, 0.1824620220590215, 0.1824620220590215, 0.1824620220590215, 0.1824620220590215, 0.1824620220590215, 0.1824620220590215, 0.1824620220590215, 0.1824620220590215, 0.1824620220590215, 0.1824620220590215, 0.1824620220590215, 0.1824620220590215, 0.1824620220590215, 0.1824620220590215, 0.1824620220590215, 0.1824620220590215, 0.1824620220590215, 0.1824620220590215, 0.1824620220590215, 0.1824620220590215, 0.1824620220590215, 0.1824620220590215, 0.1824620220590215, 204.5314994671588, 119.31021055299924, 0.15452908497926882, 0.15452908497926882, 0.15452908497926882, 0.15452908497926882, 0.15452908497926882, 0.15452908497926882, 0.15452908497926882, 0.15452908497926882, 0.15452908497926882, 0.15452908497926882, 0.15452908497926882, 0.15452908497926882, 0.15452908497926882, 0.15452908497926882, 0.15452908497926882, 0.15452908497926882, 0.15452908497926882, 0.15452908497926882, 0.15452908497926882, 0.15452908497926882, 0.15452908497926882, 0.15452908497926882, 0.15452908497926882, 0.15452908497926882, 0.15452908497926882, 0.15452908497926882, 0.15452908497926882, 0.15452908497926882, 0.15452908497926882, 0.15452908497926882, 0.15452908497926882, 0.15452908497926882, 0.15452908497926882, 0.15452908497926882, 0.15452908497926882, 0.15452908497926882, 0.15452908497926882, 0.15452908497926882, 0.15452908497926882, 0.15452908497926882, 0.15452908497926882, 0.15452908497926882, 0.15452908497926882, 0.15452908497926882, 0.15452908497926882, 0.15452908497926882, 0.15452908497926882, 0.15452908497926882, 0.15452908497926882, 0.15452908497926882, 0.15452908497926882, 0.15452908497926882, 0.15452908497926882, 0.15452908497926882, 200.44135073346382, 122.67142890919042, 0.14601070171908814, 0.14522727779334094, 0.14522727779334094, 0.14522727779334094, 0.14522727779334094, 0.14522727779334094, 0.14522727779334094, 0.14522727779334094, 0.14522727779334094, 0.14522727779334094, 0.14522727779334094, 0.14522727779334094, 0.14522727779334094, 0.14522727779334094, 0.14522727779334094, 0.14522727779334094, 0.14522727779334094, 0.14522727779334094, 0.14522727779334094, 0.14522727779334094, 0.14522727779334094, 0.14522727779334094, 0.14522727779334094, 0.14522727779334094, 0.14522727779334094, 0.14522727779334094, 0.14522727779334094, 0.14522727779334094, 0.14522727779334094, 0.14522727779334094, 0.14522727779334094, 0.14522727779334094, 0.14522727779334094, 0.14522727779334094, 0.14522727779334094, 0.14522727779334094, 0.14522727779334094, 0.14522727779334094, 0.14522727779334094, 0.14522727779334094, 0.14522727779334094, 0.14522727779334094, 0.14522727779334094, 0.14522727779334094, 0.14522727779334094, 0.14522727779334094, 0.14522727779334094, 0.14522727779334094, 0.14522727779334094, 0.14522727779334094, 0.14522727779334094, 0.14522727779334094, 300.7022407128092, 0.14355857081714912, 0.14355857081714912, 0.14355857081714912, 0.14355857081714912, 0.14355857081714912, 0.14355857081714912, 0.14355857081714912, 0.14355857081714912, 0.14355857081714912, 0.14355857081714912, 0.14355857081714912, 0.14355857081714912, 0.14355857081714912, 0.14355857081714912, 0.14355857081714912, 0.14355857081714912, 0.14355857081714912, 0.14355857081714912, 0.14355857081714912, 0.14355857081714912, 0.14355857081714912, 0.14355857081714912, 0.14355857081714912, 0.14355857081714912, 0.14355857081714912, 0.14355857081714912, 0.14355857081714912, 0.14355857081714912, 0.14355857081714912, 0.14355857081714912, 0.14355857081714912, 0.14355857081714912, 0.14355857081714912, 0.14355857081714912, 0.14355857081714912, 0.14355857081714912, 0.14355857081714912, 0.14355857081714912, 0.14355857081714912, 0.14355857081714912, 0.14355857081714912, 0.14355857081714912, 0.14355857081714912, 0.14355857081714912, 0.14355857081714912, 0.14355857081714912, 0.14355857081714912, 0.14355857081714912, 0.14355857081714912, 0.14355857081714912, 0.14355857081714912, 0.14355857081714912, 0.14355857081714912, 0.14355857081714912, 0.14355857081714912, 64.36359257626438, 51.5016609254591, 0.18096226503040272, 0.18096226503040272, 0.18096226503040272, 0.18096226503040272, 0.18096226503040272, 0.18096226503040272, 0.18096226503040272, 0.18096226503040272, 0.18096226503040272, 0.18096226503040272, 0.18096226503040272, 0.18096226503040272, 0.18096226503040272, 0.18096226503040272, 0.18096226503040272, 0.18096226503040272, 0.18096226503040272, 0.18096226503040272, 0.18096226503040272, 0.18096226503040272, 0.18096226503040272, 0.18096226503040272, 0.18096226503040272, 0.18096226503040272, 0.18096226503040272, 0.18096226503040272, 0.18096226503040272, 0.18096226503040272, 0.18096226503040272, 0.18096226503040272, 0.18096226503040272, 0.18096226503040272, 0.18096226503040272, 0.18096226503040272, 0.18096226503040272, 0.18096226503040272, 0.18096226503040272, 0.18096226503040272, 0.18096226503040272, 0.18096226503040272, 0.18096226503040272, 0.18096226503040272, 0.18096226503040272, 0.18096226503040272, 0.18096226503040272, 0.18096226503040272, 0.18096226503040272, 0.18096226503040272, 0.18096226503040272, 0.18096226503040272, 0.18096226503040272, 0.18096226503040272, 0.18096226503040272, 0.18096226503040272, 83.60153545298921, 77.09279113041383, 45.13701960174087, 0.1585986924645973, 0.1585986924645973, 0.1585986924645973, 0.1585986924645973, 0.1585986924645973, 0.1585986924645973, 0.1585986924645973, 0.1585986924645973, 0.1585986924645973, 0.1585986924645973, 0.1585986924645973, 0.1585986924645973, 0.1585986924645973, 0.1585986924645973, 0.1585986924645973, 0.1585986924645973, 0.1585986924645973, 0.1585986924645973, 0.1585986924645973, 0.1585986924645973, 0.1585986924645973, 0.1585986924645973, 0.1585986924645973, 0.1585986924645973, 0.1585986924645973, 0.1585986924645973, 0.1585986924645973, 0.1585986924645973, 0.1585986924645973, 0.1585986924645973, 0.1585986924645973, 0.1585986924645973, 0.1585986924645973, 0.1585986924645973, 0.1585986924645973, 0.1585986924645973, 0.1585986924645973, 0.1585986924645973, 0.1585986924645973, 0.1585986924645973, 0.1585986924645973, 0.1585986924645973, 0.1585986924645973, 0.1585986924645973, 0.1585986924645973, 0.1585986924645973, 0.1585986924645973, 0.1585986924645973, 0.1585986924645973, 0.1585986924645973, 0.1585986924645973, 0.1585986924645973, 0.1585986924645973, 59.12359973768159, 16.110154514233457, 0.16661594195337384, 0.16661594195337384, 0.16661594195337384, 0.16661594195337384, 0.16661594195337384, 0.16661594195337384, 0.16661594195337384, 0.16661594195337384, 0.16661594195337384, 0.16661594195337384, 0.16661594195337384, 0.16661594195337384, 0.16661594195337384, 0.16661594195337384, 0.16661594195337384, 0.16661594195337384, 0.16661594195337384, 0.16661594195337384, 0.16661594195337384, 0.16661594195337384, 0.16661594195337384, 0.16661594195337384, 0.16661594195337384, 0.16661594195337384, 0.16661594195337384, 0.16661594195337384, 0.16661594195337384, 0.16661594195337384, 0.16661594195337384, 0.16661594195337384, 0.16661594195337384, 0.16661594195337384, 0.16661594195337384, 0.16661594195337384, 0.16661594195337384, 0.16661594195337384, 0.16661594195337384, 0.16661594195337384, 0.16661594195337384, 0.16661594195337384, 0.16661594195337384, 0.16661594195337384, 0.16661594195337384, 0.16661594195337384, 0.16661594195337384, 0.16661594195337384, 0.16661594195337384, 0.16661594195337384, 0.16661594195337384, 0.16661594195337384, 0.16661594195337384, 0.16661594195337384, 0.16661594195337384, 58.62844177271648, 0.14588103726789048, 0.14588103726789048, 0.14588103726789048, 0.14588103726789048, 0.14588103726789048, 0.14588103726789048, 0.14588103726789048, 0.14588103726789048, 0.14588103726789048, 0.14588103726789048, 0.14588103726789048, 0.14588103726789048, 0.14588103726789048, 0.14588103726789048, 0.14588103726789048, 0.14588103726789048, 0.14588103726789048, 0.14588103726789048, 0.14588103726789048, 0.14588103726789048, 0.14588103726789048, 0.14588103726789048, 0.14588103726789048, 0.14588103726789048, 0.14588103726789048, 0.14588103726789048, 0.14588103726789048, 0.14588103726789048, 0.14588103726789048, 0.14588103726789048, 0.14588103726789048, 0.14588103726789048, 0.14588103726789048, 0.14588103726789048, 0.14588103726789048, 0.14588103726789048, 0.14588103726789048, 0.14588103726789048, 0.14588103726789048, 0.14588103726789048, 0.14588103726789048, 0.14588103726789048, 0.14588103726789048, 0.14588103726789048, 0.14588103726789048, 0.14588103726789048, 0.14588103726789048, 0.14588103726789048, 0.14588103726789048, 0.14588103726789048, 0.14588103726789048, 0.14588103726789048, 0.14588103726789048, 0.14588103726789048, 0.14588103726789048, 36.92532461567752, 36.92405693851592, 0.12974042227919869, 0.12974042227919869, 0.12974042227919869, 0.12974042227919869, 0.12974042227919869, 0.12974042227919869, 0.12974042227919869, 0.12974042227919869, 0.12974042227919869, 0.12974042227919869, 0.12974042227919869, 0.12974042227919869, 0.12974042227919869, 0.12974042227919869, 0.12974042227919869, 0.12974042227919869, 0.12974042227919869, 0.12974042227919869, 0.12974042227919869, 0.12974042227919869, 0.12974042227919869, 0.12974042227919869, 0.12974042227919869, 0.12974042227919869, 0.12974042227919869, 0.12974042227919869, 0.12974042227919869, 0.12974042227919869, 0.12974042227919869, 0.12974042227919869, 0.12974042227919869, 0.12974042227919869, 0.12974042227919869, 0.12974042227919869, 0.12974042227919869, 0.12974042227919869, 0.12974042227919869, 0.12974042227919869, 0.12974042227919869, 0.12974042227919869, 0.12974042227919869, 0.12974042227919869, 0.12974042227919869, 0.12974042227919869, 0.12974042227919869, 0.12974042227919869, 0.12974042227919869, 0.12974042227919869, 0.12974042227919869, 0.12974042227919869, 0.12974042227919869, 0.12974042227919869, 0.12974042227919869, 0.12974042227919869], \"Total\": [21233.0, 11910.0, 5119.0, 3777.0, 931.0, 1304.0, 593.0, 576.0, 766.0, 741.0, 724.0, 360.0, 549.0, 304.0, 373.0, 327.0, 357.0, 570.0, 271.0, 464.0, 208.0, 204.0, 239.0, 129.0, 126.0, 224.0, 123.0, 174.0, 120.0, 87.0, 21233.205845273285, 9.04533863685381, 3.8717068716256846, 3.871554440835768, 3.871843036985893, 3.8714831096305926, 3.871342767659891, 3.871342767659891, 3.8713420453216503, 3.8713415059173717, 3.871341252078811, 3.8713412496469393, 3.871130370764291, 3.8729802466923844, 3.8710627611548696, 3.871035396841729, 3.871032469960469, 3.871032467528597, 3.871031241474148, 3.871031241474148, 3.8709953155693513, 3.8709765159056224, 3.870979875917867, 3.870946318889167, 3.8715166886061287, 3.8708963392283704, 3.8708904797317856, 3.8708738621943435, 3.8714300022740553, 3.8712766665482987, 11910.247948786688, 215.72209087393833, 104.61075733163945, 3.8729802466923844, 3.871843036985893, 3.8717068716256846, 3.8715166886061287, 3.871554440835768, 3.8714831096305926, 3.8714300022740553, 3.871342767659891, 3.871342767659891, 3.8713420453216503, 3.8713415059173717, 3.8713412496469393, 3.871341252078811, 3.8712766665482987, 3.871190434499049, 3.8711222307542568, 3.871130370764291, 3.871094851403648, 3.8710627611548696, 3.871035396841729, 3.871032467528597, 3.871032469960469, 3.871031241474148, 3.871031241474148, 3.8709816062651643, 3.8709953155693513, 3.870979875917867, 5119.381750898707, 724.4234964165496, 570.8139977990145, 464.83035534977483, 3.8729802466923844, 3.8715166886061287, 3.8717068716256846, 3.871843036985893, 3.8714300022740553, 3.8712766665482987, 3.8714831096305926, 3.871554440835768, 3.871342767659891, 3.871342767659891, 3.8713420453216503, 3.8713412496469393, 3.871341252078811, 3.8713415059173717, 3.871190434499049, 3.8711222307542568, 3.871094851403648, 3.871130370764291, 3.871035396841729, 3.8709816062651643, 3.8710627611548696, 3.871032467528597, 3.871032469960469, 3.871031241474148, 3.871031241474148, 3.87091971300909, 3.8709765159056224, 3.8709953155693513, 1304.9423429782964, 766.9686806353718, 741.9680991124696, 549.1029239384551, 224.05914861754653, 174.3292375495643, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706444575665278, 3.8706444599983993, 3.870644462430271, 3.870644462430271, 3.870644462430271, 3.870644462430271, 3.870644462430271, 3.8706444648621434, 3.870644485254514, 3.870644485254514, 3.870644485254514, 3.870644485254514, 3.870644485254514, 3.870644485254514, 3.870644485254514, 3.870644485254514, 3.870644485254514, 3.870644485254514, 3.870644485254514, 3.870644485254514, 3.870644485254514, 3.870644485254514, 3.870644485254514, 3.870644485254514, 3.8706454255131812, 3.8706454483374233, 3.8706455373096182, 3.871094851403648, 3.870711013539166, 3.870676013242361, 3.870676013242361, 3.870676013242361, 3.8709816062651643, 3.8706793874245533, 3.8706793874245533, 3.8706793874245533, 3.870718173577625, 3.8706828882302022, 3.870682890662074, 3.870682890662074, 3.8706829159181884, 3.8706873580428334, 3.870717319586063, 3.870677461671288, 3.870677461671288, 3.870677461671288, 3.870677461671288, 3.870677461671288, 3.8706830051261716, 3.8706852593160197, 3.8709052490059874, 3.8708726663656043, 3.870826148738805, 3.8707639108478866, 3.8708379500298826, 3.8709114377091605, 3.8708068939390485, 3.870773873219964, 3.8707420368620933, 3.870727408027411, 3.870753920892303, 3.870902101353303, 3.8707213337344046, 3.871190434499049, 3.8711222307542568, 3.8708391354094043, 3.8714300022740553, 3.8707808802519827, 3.870749362299407, 3.8715166886061287, 3.8712766665482987, 3.8729802466923844, 3.87091971300909, 3.870837113646662, 3.870821182508997, 3.870779888415379, 3.8709065824057896, 3.871843036985893, 3.8717068716256846, 3.871342767659891, 3.871342767659891, 3.8713415059173717, 3.8713420453216503, 3.8713412496469393, 3.871341252078811, 3.8714831096305926, 3.871554440835768, 3.871130370764291, 3.8710627611548696, 3.871035396841729, 3.871032467528597, 3.871032469960469, 3.871031241474148, 3777.156632512173, 239.5641645992241, 142.30261325367482, 37.20092785675686, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706462020122303, 3.870646414940223, 3.870646414940223, 3.870646414940223, 3.8706464705519825, 3.8706464980041804, 3.8706464980041804, 3.8706464980041804, 3.8706464980041804, 3.8706464980041804, 3.8706464980041804, 3.8706464980041804, 3.8706464980041804, 3.8706464980041804, 3.8706464980041804, 3.8706464980041804, 3.8706464980041804, 3.8706464980041804, 3.8706464980041804, 3.8706465318361922, 3.8706465318361922, 3.8706465318361922, 3.8706465595241784, 3.8706465595241784, 3.8706465595241784, 3.8706465705319464, 3.870650247863274, 3.870650247863274, 3.870650247863274, 3.870650247863274, 3.870650247863274, 3.8706582864013703, 3.8706582864013703, 3.8706582864013703, 3.8706585208949167, 3.8706585208949167, 3.8706585208949167, 3.8706585208949167, 3.8706585208949167, 3.870658735553173, 3.870658735553173, 3.8706587913791286, 3.8706587913791286, 3.8706587913791286, 3.8706587913791286, 3.8706587913791286, 3.8706587913791286, 3.8706587913791286, 3.8706587913791286, 3.8706588340386605, 3.8706589467350647, 3.870650436003865, 3.8706789063755465, 3.87065920360287, 3.87065920360287, 3.870674292818998, 3.8706742952508706, 3.8706742952508706, 3.8713412496469393, 3.871341252078811, 3.8713415059173717, 3.8713420453216503, 3.871342767659891, 3.871342767659891, 3.8714831096305926, 3.870979875917867, 3.871031241474148, 3.871031241474148, 3.871130370764291, 3.871032467528597, 3.871032469960469, 3.8710627611548696, 3.8709765159056224, 3.8708904797317856, 3.871035396841729, 3.8708738621943435, 3.870840986785401, 3.870840986785401, 3.870840986785401, 3.870841332480875, 3.87084877778087, 3.870844029042176, 3.8708963392283704, 3.8707630225412024, 3.871554440835768, 3.8717068716256846, 3.8709953155693513, 3.871843036985893, 3.870946318889167, 3.8715166886061287, 3.8729802466923844, 3.8712766665482987, 3.8714300022740553, 3.871190434499049, 576.8592978691667, 373.8379137585193, 120.02104521935738, 72.88942834285996, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 9.04533863685381, 5119.381750898707, 741.9680991124696, 593.6657719960904, 360.6974215371549, 239.5641645992241, 724.4234964165496, 3777.156632512173, 215.72209087393833, 19.814182536307875, 271.36559994822966, 304.42932610601986, 204.16676741969832, 464.83035534977483, 327.6784366640328, 570.8139977990145, 142.30261325367482, 549.1029239384551, 766.9686806353718, 357.11080539736037, 44.800084356210036, 126.39684559542486, 3.870644138731605, 3.870673364694865, 593.6657719960904, 357.11080539736037, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 9.04533863685381, 5119.381750898707, 741.9680991124696, 360.6974215371549, 239.5641645992241, 724.4234964165496, 3777.156632512173, 373.8379137585193, 215.72209087393833, 19.814182536307875, 120.02104521935738, 271.36559994822966, 304.42932610601986, 204.16676741969832, 464.83035534977483, 327.6784366640328, 570.8139977990145, 142.30261325367482, 549.1029239384551, 766.9686806353718, 44.800084356210036, 126.39684559542486, 3.870644138731605, 3.870673364694865, 931.4648612422444, 931.4648612422444, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 9.04533863685381, 5119.381750898707, 741.9680991124696, 593.6657719960904, 360.6974215371549, 239.5641645992241, 724.4234964165496, 3777.156632512173, 373.8379137585193, 215.72209087393833, 19.814182536307875, 120.02104521935738, 271.36559994822966, 304.42932610601986, 204.16676741969832, 464.83035534977483, 327.6784366640328, 570.8139977990145, 142.30261325367482, 549.1029239384551, 766.9686806353718, 357.11080539736037, 44.800084356210036, 126.39684559542486, 3.870644138731605, 3.870673364694865, 360.6974215371549, 70.46037411840793, 44.800084356210036, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 9.04533863685381, 5119.381750898707, 741.9680991124696, 593.6657719960904, 239.5641645992241, 724.4234964165496, 3777.156632512173, 373.8379137585193, 215.72209087393833, 19.814182536307875, 120.02104521935738, 271.36559994822966, 304.42932610601986, 204.16676741969832, 464.83035534977483, 327.6784366640328, 570.8139977990145, 142.30261325367482, 549.1029239384551, 766.9686806353718, 357.11080539736037, 126.39684559542486, 3.870644138731605, 3.870673364694865, 327.6784366640328, 77.65534586996984, 14.055651986364364, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 9.04533863685381, 5119.381750898707, 741.9680991124696, 593.6657719960904, 360.6974215371549, 239.5641645992241, 724.4234964165496, 3777.156632512173, 373.8379137585193, 215.72209087393833, 19.814182536307875, 120.02104521935738, 271.36559994822966, 304.42932610601986, 204.16676741969832, 464.83035534977483, 570.8139977990145, 142.30261325367482, 549.1029239384551, 766.9686806353718, 357.11080539736037, 44.800084356210036, 126.39684559542486, 3.870644138731605, 3.870673364694865, 271.36559994822966, 67.51296058688828, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 9.04533863685381, 5119.381750898707, 741.9680991124696, 593.6657719960904, 360.6974215371549, 239.5641645992241, 724.4234964165496, 3777.156632512173, 373.8379137585193, 215.72209087393833, 19.814182536307875, 120.02104521935738, 304.42932610601986, 204.16676741969832, 464.83035534977483, 327.6784366640328, 570.8139977990145, 142.30261325367482, 549.1029239384551, 766.9686806353718, 357.11080539736037, 44.800084356210036, 126.39684559542486, 3.870644138731605, 3.870673364694865, 129.77020413611808, 63.62177431721509, 55.61663512972725, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 9.04533863685381, 5119.381750898707, 741.9680991124696, 593.6657719960904, 360.6974215371549, 239.5641645992241, 724.4234964165496, 3777.156632512173, 373.8379137585193, 215.72209087393833, 19.814182536307875, 120.02104521935738, 271.36559994822966, 304.42932610601986, 204.16676741969832, 464.83035534977483, 327.6784366640328, 570.8139977990145, 142.30261325367482, 549.1029239384551, 766.9686806353718, 357.11080539736037, 44.800084356210036, 126.39684559542486, 3.870644138731605, 3.870673364694865, 208.24761434620737, 123.02632543204774, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 9.04533863685381, 5119.381750898707, 741.9680991124696, 593.6657719960904, 360.6974215371549, 239.5641645992241, 724.4234964165496, 3777.156632512173, 373.8379137585193, 215.72209087393833, 19.814182536307875, 120.02104521935738, 271.36559994822966, 304.42932610601986, 204.16676741969832, 464.83035534977483, 327.6784366640328, 570.8139977990145, 142.30261325367482, 549.1029239384551, 766.9686806353718, 357.11080539736037, 44.800084356210036, 126.39684559542486, 3.870644138731605, 3.870673364694865, 204.16676741969832, 126.39684559542486, 3.871462277363435, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 9.04533863685381, 5119.381750898707, 741.9680991124696, 593.6657719960904, 360.6974215371549, 239.5641645992241, 724.4234964165496, 3777.156632512173, 373.8379137585193, 215.72209087393833, 19.814182536307875, 120.02104521935738, 271.36559994822966, 304.42932610601986, 464.83035534977483, 327.6784366640328, 570.8139977990145, 142.30261325367482, 549.1029239384551, 766.9686806353718, 357.11080539736037, 44.800084356210036, 3.870644138731605, 3.870673364694865, 304.42932610601986, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 9.04533863685381, 5119.381750898707, 741.9680991124696, 593.6657719960904, 360.6974215371549, 239.5641645992241, 724.4234964165496, 3777.156632512173, 373.8379137585193, 215.72209087393833, 19.814182536307875, 120.02104521935738, 271.36559994822966, 204.16676741969832, 464.83035534977483, 327.6784366640328, 570.8139977990145, 142.30261325367482, 549.1029239384551, 766.9686806353718, 357.11080539736037, 44.800084356210036, 126.39684559542486, 3.870644138731605, 3.870673364694865, 931.4648612422444, 68.05327427526176, 55.19134262445649, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 9.04533863685381, 5119.381750898707, 741.9680991124696, 593.6657719960904, 360.6974215371549, 239.5641645992241, 724.4234964165496, 3777.156632512173, 373.8379137585193, 215.72209087393833, 19.814182536307875, 120.02104521935738, 271.36559994822966, 304.42932610601986, 204.16676741969832, 464.83035534977483, 327.6784366640328, 570.8139977990145, 142.30261325367482, 549.1029239384551, 766.9686806353718, 357.11080539736037, 44.800084356210036, 126.39684559542486, 3.870644138731605, 3.870673364694865, 87.3135807245524, 80.80483640197701, 48.84906487330406, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 9.04533863685381, 5119.381750898707, 741.9680991124696, 593.6657719960904, 360.6974215371549, 239.5641645992241, 724.4234964165496, 3777.156632512173, 373.8379137585193, 215.72209087393833, 19.814182536307875, 120.02104521935738, 271.36559994822966, 304.42932610601986, 204.16676741969832, 464.83035534977483, 327.6784366640328, 570.8139977990145, 142.30261325367482, 549.1029239384551, 766.9686806353718, 357.11080539736037, 44.800084356210036, 126.39684559542486, 3.870644138731605, 3.870673364694865, 62.827627759756005, 19.814182536307875, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 9.04533863685381, 5119.381750898707, 741.9680991124696, 593.6657719960904, 360.6974215371549, 239.5641645992241, 724.4234964165496, 3777.156632512173, 373.8379137585193, 215.72209087393833, 120.02104521935738, 271.36559994822966, 304.42932610601986, 204.16676741969832, 464.83035534977483, 327.6784366640328, 570.8139977990145, 142.30261325367482, 549.1029239384551, 766.9686806353718, 357.11080539736037, 44.800084356210036, 126.39684559542486, 3.870644138731605, 3.870673364694865, 62.35320469947638, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 9.04533863685381, 5119.381750898707, 741.9680991124696, 593.6657719960904, 360.6974215371549, 239.5641645992241, 724.4234964165496, 3777.156632512173, 373.8379137585193, 215.72209087393833, 19.814182536307875, 120.02104521935738, 271.36559994822966, 304.42932610601986, 204.16676741969832, 464.83035534977483, 327.6784366640328, 570.8139977990145, 142.30261325367482, 549.1029239384551, 766.9686806353718, 357.11080539736037, 44.800084356210036, 126.39684559542486, 3.870644138731605, 3.870673364694865, 40.66622815742611, 40.66496048026451, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 3.8706439640277908, 9.04533863685381, 5119.381750898707, 741.9680991124696, 593.6657719960904, 360.6974215371549, 239.5641645992241, 724.4234964165496, 3777.156632512173, 373.8379137585193, 215.72209087393833, 19.814182536307875, 120.02104521935738, 271.36559994822966, 304.42932610601986, 204.16676741969832, 464.83035534977483, 327.6784366640328, 570.8139977990145, 142.30261325367482, 549.1029239384551, 766.9686806353718, 357.11080539736037, 44.800084356210036, 126.39684559542486, 3.870644138731605, 3.870673364694865], \"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\"], \"logprob\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -0.0076, -8.3205, -13.3687, -13.3687, -13.3688, -13.3689, -13.3693, -13.3693, -13.3693, -13.3693, -13.3693, -13.3693, -13.3697, -13.3693, -13.3699, -13.37, -13.37, -13.37, -13.37, -13.37, -13.3701, -13.3701, -13.3701, -13.3702, -13.3701, -13.3703, -13.3703, -13.3704, -13.3703, -13.3703, -0.1537, -4.181, -4.9225, -10.5678, -10.5707, -10.5711, -10.5714, -10.5714, -10.5716, -10.5716, -10.5719, -10.5719, -10.5719, -10.5719, -10.5719, -10.5719, -10.572, -10.5722, -10.5724, -10.5724, -10.5724, -10.5726, -10.5726, -10.5726, -10.5726, -10.5726, -10.5726, -10.5727, -10.5727, -10.5728, -0.4424, -2.4022, -2.6419, -2.8487, -10.4328, -10.4333, -10.4332, -10.4332, -10.4333, -10.4334, -10.4333, -10.4333, -10.4333, -10.4333, -10.4333, -10.4333, -10.4333, -10.4333, -10.4334, -10.4334, -10.4334, -10.4334, -10.4334, -10.4334, -10.4334, -10.4334, -10.4334, -10.4334, -10.4334, -10.4335, -10.4335, -10.4334, -1.4575, -1.9909, -2.0242, -2.3269, -3.2325, -3.488, -9.5577, -9.5577, -9.5577, -9.5577, -9.5577, -9.5577, -9.5577, -9.5577, -9.5577, -9.5577, -9.5577, -9.5577, -9.5577, -9.5577, -9.5577, -9.5577, -9.5577, -9.5577, -9.5577, -9.5577, -9.5577, -9.5577, -9.5577, -9.5577, -9.5577, -9.5577, -9.5577, -9.5577, -9.5577, -9.5577, -9.5577, -9.5577, -9.5577, -9.5577, -9.5577, -9.5577, -9.5577, -9.5577, -9.5577, -9.5577, -9.5577, -9.5577, -9.5577, -9.5577, -9.5577, -9.5577, -9.5577, -9.5577, -9.5577, -9.5577, -9.5577, -9.5576, -9.5577, -9.5577, -9.5577, -9.5577, -9.5576, -9.5577, -9.5577, -9.5577, -9.5577, -9.5577, -9.5577, -9.5577, -9.5577, -9.5577, -9.5577, -9.5577, -9.5577, -9.5577, -9.5577, -9.5577, -9.5577, -9.5577, -9.5576, -9.5576, -9.5576, -9.5576, -9.5576, -9.5576, -9.5576, -9.5576, -9.5577, -9.5577, -9.5576, -9.5576, -9.5577, -9.5576, -9.5576, -9.5576, -9.5576, -9.5576, -9.5577, -9.5576, -9.5576, -9.5575, -9.5576, -9.5576, -9.5576, -9.5576, -9.5576, -9.5576, -9.5576, -9.5576, -9.5576, -9.5576, -9.5576, -9.5576, -9.5576, -9.5576, -9.5576, -9.5576, -9.5576, -9.5576, -9.5576, -9.5576, -9.5576, -0.2023, -2.9751, -3.5069, -4.9287, -10.8076, -10.8076, -10.8076, -10.8076, -10.8076, -10.8076, -10.8076, -10.8076, -10.8076, -10.8076, -10.8076, -10.8076, -10.8076, -10.8076, -10.8076, -10.8076, -10.8076, -10.8076, -10.8076, -10.8076, -10.8076, -10.8076, -10.8076, -10.8076, -10.8076, -10.8076, -10.8076, -10.8076, -10.8076, -10.8076, -10.8076, -10.8076, -10.8076, -10.8076, -10.8076, -10.8076, -10.8076, -10.8076, -10.8076, -10.8076, -10.8076, -10.8076, -10.8076, -10.8076, -10.8076, -10.8076, -10.8076, -10.8076, -10.8076, -10.8076, -10.8076, -10.8076, -10.8076, -10.8076, -10.8076, -10.8076, -10.8076, -10.8076, -10.8076, -10.8076, -10.8076, -10.8076, -10.8076, -10.8076, -10.8076, -10.8076, -10.8076, -10.8076, -10.8076, -10.8076, -10.8076, -10.8076, -10.8076, -10.8076, -10.8076, -10.8076, -10.8076, -10.8076, -10.8076, -10.8076, -10.8076, -10.8076, -10.8076, -10.8076, -10.8076, -10.8076, -10.8076, -10.8076, -10.8076, -10.8076, -10.8076, -10.8076, -10.8076, -10.8076, -10.8076, -10.8076, -10.8076, -10.8076, -10.8076, -10.8076, -10.8076, -10.8076, -10.8076, -10.8076, -10.8076, -10.8076, -10.8076, -10.8076, -10.8076, -10.8076, -10.8076, -10.8076, -10.8076, -10.8076, -10.8076, -10.8076, -10.8076, -10.8076, -10.8076, -10.8076, -1.3759, -1.8131, -2.9702, -3.4893, -9.1404, -9.1404, -9.1404, -9.1404, -9.1404, -9.1404, -9.1404, -9.1404, -9.1404, -9.1404, -9.1404, -9.1404, -9.1404, -9.1404, -9.1404, -9.1404, -9.1404, -9.1404, -9.1404, -9.1404, -9.1404, -9.1404, -9.1404, -9.1404, -9.1404, -9.1404, -9.1404, -9.1404, -9.1404, -9.1404, -9.1404, -9.1404, -9.1404, -9.1404, -9.1404, -9.1404, -9.1404, -9.1404, -9.1404, -9.1404, -9.1404, -9.1404, -9.1404, -9.1404, -9.1404, -9.1404, -9.1404, -9.1404, -9.1404, -9.1404, -1.2896, -1.802, -9.033, -9.033, -9.033, -9.033, -9.033, -9.033, -9.033, -9.033, -9.033, -9.033, -9.033, -9.033, -9.033, -9.033, -9.033, -9.033, -9.033, -9.033, -9.033, -9.033, -9.033, -9.033, -9.033, -9.033, -9.033, -9.033, -9.033, -9.033, -9.033, -9.033, -9.033, -9.033, -9.033, -9.033, -9.033, -9.033, -9.033, -9.033, -9.033, -9.033, -9.033, -9.033, -9.033, -9.033, -9.033, -9.033, -9.033, -9.033, -9.033, -9.033, -9.033, -9.033, -9.033, -0.7021, -9.137, -9.137, -9.137, -9.137, -9.137, -9.137, -9.137, -9.137, -9.137, -9.137, -9.137, -9.137, -9.137, -9.137, -9.137, -9.137, -9.137, -9.137, -9.137, -9.137, -9.137, -9.137, -9.137, -9.137, -9.137, -9.137, -9.137, -9.137, -9.137, -9.137, -9.137, -9.137, -9.137, -9.137, -9.137, -9.137, -9.137, -9.137, -9.137, -9.137, -9.137, -9.137, -9.137, -9.137, -9.137, -9.137, -9.137, -9.137, -9.137, -9.137, -9.137, -9.137, -9.137, -9.137, -9.137, -1.4784, -3.1542, -3.6387, -8.8047, -8.8047, -8.8047, -8.8047, -8.8047, -8.8047, -8.8047, -8.8047, -8.8047, -8.8047, -8.8047, -8.8047, -8.8047, -8.8047, -8.8047, -8.8047, -8.8047, -8.8047, -8.8047, -8.8047, -8.8047, -8.8047, -8.8047, -8.8047, -8.8047, -8.8047, -8.8047, -8.8047, -8.8047, -8.8047, -8.8047, -8.8047, -8.8047, -8.8047, -8.8047, -8.8047, -8.8047, -8.8047, -8.8047, -8.8047, -8.8047, -8.8047, -8.8047, -8.8047, -8.8047, -8.8047, -8.8047, -8.8047, -8.8047, -8.8047, -8.8047, -1.4969, -2.9736, -4.9353, -8.7838, -8.7838, -8.7838, -8.7838, -8.7838, -8.7838, -8.7838, -8.7838, -8.7838, -8.7838, -8.7838, -8.7838, -8.7838, -8.7838, -8.7838, -8.7838, -8.7838, -8.7838, -8.7838, -8.7838, -8.7838, -8.7838, -8.7838, -8.7838, -8.7838, -8.7838, -8.7838, -8.7838, -8.7838, -8.7838, -8.7838, -8.7838, -8.7838, -8.7838, -8.7838, -8.7838, -8.7838, -8.7838, -8.7838, -8.7838, -8.7838, -8.7838, -8.7838, -8.7838, -8.7838, -8.7838, -8.7838, -8.7838, -8.7838, -8.7838, -8.7838, -8.7838, -1.5345, -2.968, -8.7631, -8.7631, -8.7631, -8.7631, -8.7631, -8.7631, -8.7631, -8.7631, -8.7631, -8.7631, -8.7631, -8.7631, -8.7631, -8.7631, -8.7631, -8.7631, -8.7631, -8.7631, -8.7631, -8.7631, -8.7631, -8.7631, -8.7631, -8.7631, -8.7631, -8.7631, -8.7631, -8.7631, -8.7631, -8.7631, -8.7631, -8.7631, -8.7631, -8.7631, -8.7631, -8.7631, -8.7631, -8.7631, -8.7631, -8.7631, -8.7631, -8.7631, -8.7631, -8.7631, -8.7631, -8.7631, -8.7631, -8.7631, -8.7631, -8.7631, -8.7631, -8.7631, -8.7631, -2.1597, -2.9034, -3.0468, -8.6979, -8.6979, -8.6979, -8.6979, -8.6979, -8.6979, -8.6979, -8.6979, -8.6979, -8.6979, -8.6979, -8.6979, -8.6979, -8.6979, -8.6979, -8.6979, -8.6979, -8.6979, -8.6979, -8.6979, -8.6979, -8.6979, -8.6979, -8.6979, -8.6979, -8.6979, -8.6979, -8.6979, -8.6979, -8.6979, -8.6979, -8.6979, -8.6979, -8.6979, -8.6979, -8.6979, -8.6979, -8.6979, -8.6979, -8.6979, -8.6979, -8.6979, -8.6979, -8.6979, -8.6979, -8.6979, -8.6979, -8.6979, -8.6979, -8.6979, -8.6979, -8.6979, -8.6979, -1.634, -2.173, -8.8221, -8.8221, -8.8221, -8.8221, -8.8221, -8.8221, -8.8221, -8.8221, -8.8221, -8.8221, -8.8221, -8.8221, -8.8221, -8.8221, -8.8221, -8.8221, -8.8221, -8.8221, -8.8221, -8.8221, -8.8221, -8.8221, -8.8221, -8.8221, -8.8221, -8.8221, -8.8221, -8.8221, -8.8221, -8.8221, -8.8221, -8.8221, -8.8221, -8.8221, -8.8221, -8.8221, -8.8221, -8.8221, -8.8221, -8.8221, -8.8221, -8.8221, -8.8221, -8.8221, -8.8221, -8.8221, -8.8221, -8.8221, -8.8221, -8.8221, -8.8221, -8.8221, -8.8221, -8.8221, -1.611, -2.102, -8.8356, -8.841, -8.841, -8.841, -8.841, -8.841, -8.841, -8.841, -8.841, -8.841, -8.841, -8.841, -8.841, -8.841, -8.841, -8.841, -8.841, -8.841, -8.841, -8.841, -8.841, -8.841, -8.841, -8.841, -8.841, -8.841, -8.841, -8.841, -8.841, -8.841, -8.841, -8.841, -8.841, -8.841, -8.841, -8.841, -8.841, -8.841, -8.841, -8.841, -8.841, -8.841, -8.841, -8.841, -8.841, -8.841, -8.841, -8.841, -8.841, -8.841, -8.841, -8.841, -1.175, -8.8221, -8.8221, -8.8221, -8.8221, -8.8221, -8.8221, -8.8221, -8.8221, -8.8221, -8.8221, -8.8221, -8.8221, -8.8221, -8.8221, -8.8221, -8.8221, -8.8221, -8.8221, -8.8221, -8.8221, -8.8221, -8.8221, -8.8221, -8.8221, -8.8221, -8.8221, -8.8221, -8.8221, -8.8221, -8.8221, -8.8221, -8.8221, -8.8221, -8.8221, -8.8221, -8.8221, -8.8221, -8.8221, -8.8221, -8.8221, -8.8221, -8.8221, -8.8221, -8.8221, -8.8221, -8.8221, -8.8221, -8.8221, -8.8221, -8.8221, -8.8221, -8.8221, -8.8221, -8.8221, -8.8221, -2.7066, -2.9295, -8.5806, -8.5806, -8.5806, -8.5806, -8.5806, -8.5806, -8.5806, -8.5806, -8.5806, -8.5806, -8.5806, -8.5806, -8.5806, -8.5806, -8.5806, -8.5806, -8.5806, -8.5806, -8.5806, -8.5806, -8.5806, -8.5806, -8.5806, -8.5806, -8.5806, -8.5806, -8.5806, -8.5806, -8.5806, -8.5806, -8.5806, -8.5806, -8.5806, -8.5806, -8.5806, -8.5806, -8.5806, -8.5806, -8.5806, -8.5806, -8.5806, -8.5806, -8.5806, -8.5806, -8.5806, -8.5806, -8.5806, -8.5806, -8.5806, -8.5806, -8.5806, -8.5806, -8.5806, -8.5806, -2.4294, -2.5104, -3.0457, -8.6968, -8.6968, -8.6968, -8.6968, -8.6968, -8.6968, -8.6968, -8.6968, -8.6968, -8.6968, -8.6968, -8.6968, -8.6968, -8.6968, -8.6968, -8.6968, -8.6968, -8.6968, -8.6968, -8.6968, -8.6968, -8.6968, -8.6968, -8.6968, -8.6968, -8.6968, -8.6968, -8.6968, -8.6968, -8.6968, -8.6968, -8.6968, -8.6968, -8.6968, -8.6968, -8.6968, -8.6968, -8.6968, -8.6968, -8.6968, -8.6968, -8.6968, -8.6968, -8.6968, -8.6968, -8.6968, -8.6968, -8.6968, -8.6968, -8.6968, -8.6968, -8.6968, -8.6968, -2.6728, -3.973, -8.5445, -8.5445, -8.5445, -8.5445, -8.5445, -8.5445, -8.5445, -8.5445, -8.5445, -8.5445, -8.5445, -8.5445, -8.5445, -8.5445, -8.5445, -8.5445, -8.5445, -8.5445, -8.5445, -8.5445, -8.5445, -8.5445, -8.5445, -8.5445, -8.5445, -8.5445, -8.5445, -8.5445, -8.5445, -8.5445, -8.5445, -8.5445, -8.5445, -8.5445, -8.5445, -8.5445, -8.5445, -8.5445, -8.5445, -8.5445, -8.5445, -8.5445, -8.5445, -8.5445, -8.5445, -8.5445, -8.5445, -8.5445, -8.5445, -8.5445, -8.5445, -8.5445, -8.5445, -2.5388, -8.535, -8.535, -8.535, -8.535, -8.535, -8.535, -8.535, -8.535, -8.535, -8.535, -8.535, -8.535, -8.535, -8.535, -8.535, -8.535, -8.535, -8.535, -8.535, -8.535, -8.535, -8.535, -8.535, -8.535, -8.535, -8.535, -8.535, -8.535, -8.535, -8.535, -8.535, -8.535, -8.535, -8.535, -8.535, -8.535, -8.535, -8.535, -8.535, -8.535, -8.535, -8.535, -8.535, -8.535, -8.535, -8.535, -8.535, -8.535, -8.535, -8.535, -8.535, -8.535, -8.535, -8.535, -8.535, -2.916, -2.9161, -8.5672, -8.5672, -8.5672, -8.5672, -8.5672, -8.5672, -8.5672, -8.5672, -8.5672, -8.5672, -8.5672, -8.5672, -8.5672, -8.5672, -8.5672, -8.5672, -8.5672, -8.5672, -8.5672, -8.5672, -8.5672, -8.5672, -8.5672, -8.5672, -8.5672, -8.5672, -8.5672, -8.5672, -8.5672, -8.5672, -8.5672, -8.5672, -8.5672, -8.5672, -8.5672, -8.5672, -8.5672, -8.5672, -8.5672, -8.5672, -8.5672, -8.5672, -8.5672, -8.5672, -8.5672, -8.5672, -8.5672, -8.5672, -8.5672, -8.5672, -8.5672, -8.5672, -8.5672, -8.5672], \"loglift\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 1.2177, 0.6658, -3.5338, -3.5338, -3.5339, -3.534, -3.5343, -3.5343, -3.5343, -3.5343, -3.5343, -3.5343, -3.5347, -3.5347, -3.5349, -3.5349, -3.5349, -3.5349, -3.5349, -3.5349, -3.535, -3.535, -3.5351, -3.5351, -3.5352, -3.5352, -3.5352, -3.5353, -3.5353, -3.5353, 1.6497, 1.6336, 1.6159, -0.7333, -0.7359, -0.7362, -0.7365, -0.7365, -0.7367, -0.7367, -0.7369, -0.7369, -0.7369, -0.7369, -0.7369, -0.7369, -0.737, -0.7372, -0.7373, -0.7374, -0.7374, -0.7375, -0.7376, -0.7376, -0.7376, -0.7376, -0.7376, -0.7376, -0.7376, -0.7377, 2.2053, 2.201, 2.1997, 2.1982, -0.5983, -0.5983, -0.5983, -0.5983, -0.5983, -0.5984, -0.5984, -0.5984, -0.5984, -0.5984, -0.5984, -0.5984, -0.5984, -0.5984, -0.5984, -0.5984, -0.5984, -0.5984, -0.5984, -0.5984, -0.5984, -0.5984, -0.5984, -0.5984, -0.5984, -0.5984, -0.5984, -0.5984, 2.5571, 2.5552, 2.5551, 2.5534, 2.5442, 2.5397, 0.2775, 0.2775, 0.2775, 0.2775, 0.2775, 0.2775, 0.2775, 0.2775, 0.2775, 0.2775, 0.2775, 0.2775, 0.2775, 0.2775, 0.2775, 0.2775, 0.2775, 0.2775, 0.2775, 0.2775, 0.2775, 0.2775, 0.2775, 0.2775, 0.2775, 0.2775, 0.2775, 0.2775, 0.2775, 0.2775, 0.2775, 0.2775, 0.2775, 0.2775, 0.2775, 0.2775, 0.2775, 0.2775, 0.2775, 0.2775, 0.2775, 0.2775, 0.2775, 0.2775, 0.2775, 0.2775, 0.2775, 0.2775, 0.2775, 0.2775, 0.2775, 0.2774, 0.2775, 0.2775, 0.2775, 0.2775, 0.2774, 0.2775, 0.2775, 0.2775, 0.2775, 0.2775, 0.2775, 0.2775, 0.2775, 0.2775, 0.2775, 0.2775, 0.2775, 0.2775, 0.2775, 0.2775, 0.2775, 0.2775, 0.2775, 0.2775, 0.2775, 0.2775, 0.2775, 0.2775, 0.2775, 0.2775, 0.2775, 0.2775, 0.2775, 0.2775, 0.2775, 0.2774, 0.2774, 0.2775, 0.2774, 0.2775, 0.2775, 0.2773, 0.2774, 0.2771, 0.2775, 0.2775, 0.2775, 0.2775, 0.2775, 0.2773, 0.2773, 0.2774, 0.2774, 0.2774, 0.2774, 0.2774, 0.2774, 0.2773, 0.2773, 0.2774, 0.2774, 0.2774, 0.2774, 0.2774, 0.2774, 2.7496, 2.7347, 2.7237, 2.6435, -0.9724, -0.9724, -0.9724, -0.9724, -0.9724, -0.9724, -0.9724, -0.9724, -0.9724, -0.9724, -0.9724, -0.9724, -0.9724, -0.9724, -0.9724, -0.9724, -0.9724, -0.9724, -0.9724, -0.9724, -0.9724, -0.9724, -0.9724, -0.9724, -0.9724, -0.9724, -0.9724, -0.9724, -0.9724, -0.9724, -0.9724, -0.9724, -0.9724, -0.9724, -0.9724, -0.9724, -0.9724, -0.9724, -0.9724, -0.9724, -0.9724, -0.9724, -0.9724, -0.9724, -0.9724, -0.9724, -0.9724, -0.9724, -0.9724, -0.9724, -0.9724, -0.9724, -0.9724, -0.9724, -0.9724, -0.9724, -0.9724, -0.9724, -0.9724, -0.9724, -0.9724, -0.9724, -0.9724, -0.9724, -0.9724, -0.9724, -0.9724, -0.9724, -0.9724, -0.9724, -0.9724, -0.9724, -0.9724, -0.9724, -0.9724, -0.9724, -0.9724, -0.9724, -0.9724, -0.9724, -0.9724, -0.9724, -0.9724, -0.9724, -0.9726, -0.9726, -0.9726, -0.9726, -0.9726, -0.9726, -0.9726, -0.9725, -0.9725, -0.9725, -0.9725, -0.9725, -0.9725, -0.9725, -0.9725, -0.9725, -0.9725, -0.9725, -0.9725, -0.9725, -0.9725, -0.9725, -0.9725, -0.9725, -0.9725, -0.9725, -0.9727, -0.9727, -0.9725, -0.9727, -0.9725, -0.9726, -0.973, -0.9726, -0.9726, -0.9726, 3.4551, 3.4516, 3.4307, 3.4103, 0.6948, 0.6948, 0.6948, 0.6948, 0.6948, 0.6948, 0.6948, 0.6948, 0.6948, 0.6948, 0.6948, 0.6948, 0.6948, 0.6948, 0.6948, 0.6948, 0.6948, 0.6948, 0.6948, 0.6948, 0.6948, 0.6948, 0.6948, 0.6948, 0.6948, 0.6948, -0.1541, -6.4926, -4.5611, -4.3381, -3.8399, -3.4306, -4.5372, -6.1885, -3.3258, -0.9382, -3.5553, -3.6703, -3.2708, -4.0935, -3.7438, -4.2989, -2.9098, -4.2601, -4.5943, -3.8299, -1.754, -2.7912, 0.6948, 0.6948, 3.5126, 3.5086, 0.8022, 0.8022, 0.8022, 0.8022, 0.8022, 0.8022, 0.8022, 0.8022, 0.8022, 0.8022, 0.8022, 0.8022, 0.8022, 0.8022, 0.8022, 0.8022, 0.8022, 0.8022, 0.8022, 0.8022, 0.8022, 0.8022, 0.8022, 0.8022, 0.8022, 0.8022, 0.8022, 0.8022, -0.0467, -6.3852, -4.4537, -3.7324, -3.3232, -4.4298, -6.0811, -3.7682, -3.2184, -0.8308, -2.6321, -3.4479, -3.5628, -3.1633, -3.9861, -3.6364, -4.1915, -2.8024, -4.1527, -4.4869, -1.6466, -2.6838, 0.8022, 0.8022, -4.6812, 3.6497, 0.6981, 0.6981, 0.6981, 0.6981, 0.6981, 0.6981, 0.6981, 0.6981, 0.6981, 0.6981, 0.6981, 0.6981, 0.6981, 0.6981, 0.6981, 0.6981, 0.6981, 0.6981, 0.6981, 0.6981, 0.6981, 0.6981, 0.6981, 0.6981, 0.6981, 0.6981, 0.6981, 0.6981, 0.6981, -0.1507, -6.4893, -4.5578, -4.3348, -3.8365, -3.4273, -4.5338, -6.1852, -3.8723, -3.3225, -0.9349, -2.7361, -3.5519, -3.6669, -3.2674, -4.0901, -3.7405, -4.2955, -2.9064, -4.2567, -4.5909, -3.8265, -1.7507, -2.7879, 0.6981, 0.6981, 3.8221, 3.7793, 3.7476, 1.0305, 1.0305, 1.0305, 1.0305, 1.0305, 1.0305, 1.0305, 1.0305, 1.0305, 1.0305, 1.0305, 1.0305, 1.0305, 1.0305, 1.0305, 1.0305, 1.0305, 1.0305, 1.0305, 1.0305, 1.0305, 1.0305, 1.0305, 1.0305, 1.0305, 1.0305, 1.0305, 0.1817, -6.1569, -4.2254, -4.0024, -3.0949, -4.2015, -5.8528, -3.5399, -2.9901, -0.6025, -2.4038, -3.2196, -3.3345, -2.935, -3.7578, -3.4081, -3.9632, -2.5741, -3.9244, -4.2585, -3.4941, -2.4555, 1.0305, 1.0305, 3.8997, 3.8627, 3.6103, 1.0513, 1.0513, 1.0513, 1.0513, 1.0513, 1.0513, 1.0513, 1.0513, 1.0513, 1.0513, 1.0513, 1.0513, 1.0513, 1.0513, 1.0513, 1.0513, 1.0513, 1.0513, 1.0513, 1.0513, 1.0513, 1.0513, 1.0513, 1.0513, 1.0513, 1.0513, 1.0513, 0.2025, -6.136, -4.2045, -3.9815, -3.4833, -3.0741, -4.1806, -5.832, -3.5191, -2.9692, -0.5816, -2.3829, -3.1987, -3.3137, -2.9142, -3.7369, -3.9423, -2.5532, -3.9035, -4.2377, -3.4733, -1.3974, -2.4347, 1.0513, 1.0513, 4.0506, 4.0083, 1.072, 1.072, 1.072, 1.072, 1.072, 1.072, 1.072, 1.072, 1.072, 1.072, 1.072, 1.072, 1.072, 1.072, 1.072, 1.072, 1.072, 1.072, 1.072, 1.072, 1.072, 1.072, 1.072, 1.072, 1.072, 1.072, 1.072, 1.072, 0.2232, -6.1153, -4.1838, -3.9609, -3.4626, -3.0534, -4.1599, -5.8113, -3.4984, -2.9485, -0.5609, -2.3622, -3.293, -2.8935, -3.7162, -3.3666, -3.9216, -2.5325, -3.8828, -4.217, -3.4526, -1.3768, -2.414, 1.072, 1.072, 4.1631, 4.1322, 4.1233, 1.1373, 1.1373, 1.1373, 1.1373, 1.1373, 1.1373, 1.1373, 1.1373, 1.1373, 1.1373, 1.1373, 1.1373, 1.1373, 1.1373, 1.1373, 1.1373, 1.1373, 1.1373, 1.1373, 1.1373, 1.1373, 1.1373, 1.1373, 1.1373, 1.1373, 1.1373, 1.1373, 0.2885, -6.0501, -4.1186, -3.8956, -3.3973, -2.9881, -4.0947, -5.746, -3.4331, -2.8833, -0.4957, -2.2969, -3.1127, -3.2277, -2.8282, -3.651, -3.3013, -3.8563, -2.4672, -3.8176, -4.1517, -3.3873, -1.3115, -2.3487, 1.1373, 1.1373, 4.2158, 4.2032, 1.013, 1.013, 1.013, 1.013, 1.013, 1.013, 1.013, 1.013, 1.013, 1.013, 1.013, 1.013, 1.013, 1.013, 1.013, 1.013, 1.013, 1.013, 1.013, 1.013, 1.013, 1.013, 1.013, 1.013, 1.013, 1.013, 1.013, 1.013, 0.1642, -6.1743, -4.2429, -4.0199, -3.5216, -3.1124, -4.2189, -5.8703, -3.5574, -3.0075, -0.6199, -2.4212, -3.237, -3.352, -2.9525, -3.7752, -3.4256, -3.9806, -2.5915, -3.9418, -4.276, -3.5116, -1.4358, -2.473, 1.013, 1.013, 4.2586, 4.2471, 0.9993, 0.9942, 0.9942, 0.9942, 0.9942, 0.9942, 0.9942, 0.9942, 0.9942, 0.9942, 0.9942, 0.9942, 0.9942, 0.9942, 0.9942, 0.9942, 0.9942, 0.9942, 0.9942, 0.9942, 0.9942, 0.9942, 0.9942, 0.9942, 0.9942, 0.9942, 0.9942, 0.9942, 0.1453, -6.1932, -4.2617, -4.0387, -3.5405, -3.1312, -4.2378, -5.8891, -3.5762, -3.0264, -0.6388, -2.4401, -3.2559, -3.3709, -3.7941, -3.4445, -3.9995, -2.6104, -3.9607, -4.2949, -3.5305, -1.4546, 0.9942, 0.9942, 4.2952, 1.013, 1.013, 1.013, 1.013, 1.013, 1.013, 1.013, 1.013, 1.013, 1.013, 1.013, 1.013, 1.013, 1.013, 1.013, 1.013, 1.013, 1.013, 1.013, 1.013, 1.013, 1.013, 1.013, 1.013, 1.013, 1.013, 1.013, 1.013, 1.013, 0.1642, -6.1743, -4.2428, -4.0199, -3.5216, -3.1124, -4.2189, -5.8703, -3.5574, -3.0075, -0.6199, -2.4212, -3.237, -2.9525, -3.7752, -3.4256, -3.9806, -2.5915, -3.9418, -4.276, -3.5116, -1.4358, -2.473, 1.013, 1.013, -4.4703, 4.2617, 4.2483, 1.2546, 1.2546, 1.2546, 1.2546, 1.2546, 1.2546, 1.2546, 1.2546, 1.2546, 1.2546, 1.2546, 1.2546, 1.2546, 1.2546, 1.2546, 1.2546, 1.2546, 1.2546, 1.2546, 1.2546, 1.2546, 1.2546, 1.2546, 1.2546, 1.2546, 1.2546, 1.2546, 1.2546, 0.4057, -5.9328, -4.0013, -3.7783, -3.2801, -2.8708, -3.9774, -5.6287, -3.3158, -2.766, -0.3784, -2.1797, -2.9955, -3.1105, -2.711, -3.5337, -3.184, -3.7391, -2.35, -3.7003, -4.0345, -3.2701, -1.1942, -2.2314, 1.2546, 1.2546, 4.2897, 4.2861, 4.2541, 1.1383, 1.1383, 1.1383, 1.1383, 1.1383, 1.1383, 1.1383, 1.1383, 1.1383, 1.1383, 1.1383, 1.1383, 1.1383, 1.1383, 1.1383, 1.1383, 1.1383, 1.1383, 1.1383, 1.1383, 1.1383, 1.1383, 1.1383, 1.1383, 1.1383, 1.1383, 1.1383, 0.2895, -6.049, -4.1175, -3.8946, -3.3963, -2.9871, -4.0936, -5.745, -3.4321, -2.8822, -0.4946, -2.2959, -3.1117, -3.2267, -2.8272, -3.6499, -3.3003, -3.8553, -2.4662, -3.8165, -4.1507, -3.3863, -1.3104, -2.3477, 1.1383, 1.1383, 4.3754, 4.2292, 1.2906, 1.2906, 1.2906, 1.2906, 1.2906, 1.2906, 1.2906, 1.2906, 1.2906, 1.2906, 1.2906, 1.2906, 1.2906, 1.2906, 1.2906, 1.2906, 1.2906, 1.2906, 1.2906, 1.2906, 1.2906, 1.2906, 1.2906, 1.2906, 1.2906, 1.2906, 1.2906, 1.2906, 0.4418, -5.8967, -3.9653, -3.7423, -3.244, -2.8348, -3.9413, -5.5927, -3.2798, -2.7299, -2.1436, -2.9594, -3.0744, -2.6749, -3.4976, -3.148, -3.703, -2.3139, -3.6642, -3.9984, -3.234, -1.1582, -2.1954, 1.2906, 1.2906, 4.5169, 1.3001, 1.3001, 1.3001, 1.3001, 1.3001, 1.3001, 1.3001, 1.3001, 1.3001, 1.3001, 1.3001, 1.3001, 1.3001, 1.3001, 1.3001, 1.3001, 1.3001, 1.3001, 1.3001, 1.3001, 1.3001, 1.3001, 1.3001, 1.3001, 1.3001, 1.3001, 1.3001, 1.3001, 1.3001, 0.4513, -5.8872, -3.9557, -3.7327, -3.2345, -2.8253, -3.9318, -5.5832, -3.2703, -2.7204, -0.3328, -2.1341, -2.9499, -3.0649, -2.6654, -3.4881, -3.1385, -3.6935, -2.3044, -3.6547, -3.9889, -3.2245, -1.1486, -2.1859, 1.3001, 1.3001, 4.5671, 4.5671, 1.268, 1.268, 1.268, 1.268, 1.268, 1.268, 1.268, 1.268, 1.268, 1.268, 1.268, 1.268, 1.268, 1.268, 1.268, 1.268, 1.268, 1.268, 1.268, 1.268, 1.268, 1.268, 1.268, 1.268, 1.268, 1.268, 1.268, 1.268, 0.4192, -5.9194, -3.9879, -3.7649, -3.2666, -2.8574, -3.964, -5.6153, -3.3024, -2.7526, -0.365, -2.1663, -2.9821, -3.097, -2.6975, -3.5203, -3.1706, -3.7256, -2.3365, -3.6869, -4.021, -3.2566, -1.1808, -2.218, 1.268, 1.268]}, \"token.table\": {\"Topic\": [3, 20, 8, 12, 9, 11, 5, 6, 1, 2, 7, 17, 15, 5, 5, 13, 7, 11, 13, 3, 6, 6, 3, 16, 4, 4, 4, 4, 14, 12, 19, 20, 10, 12, 9, 10, 14, 6, 17, 10, 18, 4, 1, 9, 5, 4, 2, 18, 3, 16, 2, 17], \"Freq\": [0.99933942201163, 0.9098742397144788, 0.996280201877263, 0.9430733525418971, 0.989749243226087, 0.9479661304088842, 0.9988995339837394, 0.9466393353427781, 0.9998019213253084, 0.9654838811634587, 0.9884887118081285, 0.952913259015225, 0.9887352307680582, 0.887074648435312, 0.9767916190844125, 0.967272651459694, 0.9938251922731457, 0.9875975438711769, 0.984405034571929, 0.9917596703707258, 0.9933098107572811, 0.9897337492606532, 0.9933183176766499, 0.942176753224294, 0.9948254984387576, 0.9943491032315048, 0.980902586414297, 0.9946519276001, 0.9795913533218027, 0.9709470740127414, 0.9462224160628502, 0.9098458764546961, 0.9887742486155587, 0.9349720614831991, 0.9508890754313509, 0.9529285997117245, 0.9731255508836225, 0.9664971654595386, 0.9212049425452243, 0.711457569503085, 0.9390773152474845, 0.9863466917712507, 0.5527709023107533, 0.915176848195303, 0.9851222965455341, 0.9969789140497206, 0.9997272979705667, 0.8075024024171223, 0.9952741781106158, 0.9404396876061087, 0.9827458983970566, 0.9620496525620026], \"Term\": [\"africa\", \"amazingly\", \"amp\", \"atlanta\", \"blow\", \"cdcdirector\", \"coronavirus\", \"courageous\", \"covid\", \"crazy\", \"desperate\", \"doctor\", \"dr\", \"easy\", \"expert\", \"find\", \"full\", \"globalhlthtwit\", \"go\", \"good\", \"government\", \"head\", \"health\", \"hodkinson\", \"know\", \"leader\", \"medical\", \"midst\", \"moeti\", \"pfizer\", \"pleased\", \"policy\", \"public\", \"qualified\", \"realjoelsmalley\", \"remember\", \"research\", \"rise\", \"roger\", \"sell\", \"speak\", \"still\", \"telglobalhealth\", \"thank\", \"third\", \"today\", \"vaccine\", \"warnedcase\", \"wave\", \"way\", \"whoafro\", \"yet\"]}, \"R\": 30, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [15, 16, 2, 14, 8, 5, 17, 19, 7, 3, 13, 6, 11, 18, 9, 20, 1, 12, 10, 4]};\n\nfunction LDAvis_load_lib(url, callback){\n  var s = document.createElement('script');\n  s.src = url;\n  s.async = true;\n  s.onreadystatechange = s.onload = callback;\n  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n  document.getElementsByTagName(\"head\")[0].appendChild(s);\n}\n\nif(typeof(LDAvis) !== \"undefined\"){\n   // already loaded: just create the visualization\n   !function(LDAvis){\n       new LDAvis(\"#\" + \"ldavis_el464026088655212169618053949\", ldavis_el464026088655212169618053949_data);\n   }(LDAvis);\n}else if(typeof define === \"function\" && define.amd){\n   // require.js is available: use it to load d3/LDAvis\n   require.config({paths: {d3: \"https://d3js.org/d3.v5\"}});\n   require([\"d3\"], function(d3){\n      window.d3 = d3;\n      LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.3.1/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n        new LDAvis(\"#\" + \"ldavis_el464026088655212169618053949\", ldavis_el464026088655212169618053949_data);\n      });\n    });\n}else{\n    // require.js not available: dynamically load d3 & LDAvis\n    LDAvis_load_lib(\"https://d3js.org/d3.v5.js\", function(){\n         LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.3.1/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n                 new LDAvis(\"#\" + \"ldavis_el464026088655212169618053949\", ldavis_el464026088655212169618053949_data);\n            })\n         });\n}\n</script>"
     },
     "metadata": {},
     "execution_count": 27
    }
   ],
   "source": [
    "# Visualize the topics\n",
    "pyLDAvis.enable_notebook()\n",
    "vis = pyLDAvis.gensim_models.prepare(lda_model, corpus, id2word)\n",
    "vis"
   ]
  },
  {
   "source": [
    "Saving generated Topic LDA Model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['../trained_models/topicLDAmodel']"
      ]
     },
     "metadata": {},
     "execution_count": 32
    }
   ],
   "source": [
    "joblib.dump(lda_model, '../trained_models/topicLDAmodel')\n",
    "# then reload it with\n",
    "# lda_model = joblib.load('lda_model.jl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "description = {'sentiment_analysis':{'name':best_model_name,'score':best_score}, 'topic_modeling':{'perplexity_score':perplexity_score, 'coherence_score':coherence_lda}}\n",
    "pickle.dump(description, 'trainedModelsData.pk')\n",
    "# # then reload it with\n",
    "# lda_model = pickle.load('lda_model.pk')"
   ]
  }
 ]
}